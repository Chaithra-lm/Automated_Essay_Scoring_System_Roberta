{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:10.717399Z",
     "iopub.status.busy": "2024-06-02T09:39:10.716679Z",
     "iopub.status.idle": "2024-06-02T09:39:13.948996Z",
     "shell.execute_reply": "2024-06-02T09:39:13.947581Z",
     "shell.execute_reply.started": "2024-06-02T09:39:10.717351Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai in /opt/conda/lib/python3.9/site-packages (2.7.15)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.41.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.23.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.5.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (3.6.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (1.9.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (5.9.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (1.12.1)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.9/site-packages (3.7.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from fastai) (6.0)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.9/site-packages (from fastai) (1.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.9/site-packages (from fastai) (9.4.0)\n",
      "Requirement already satisfied: torchvision>=0.11 in /opt/conda/lib/python3.9/site-packages (from fastai) (0.13.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from fastai) (21.3)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (from fastai) (22.2.2)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.9/site-packages (from fastai) (0.0.7)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from fastai) (2.28.1)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.9/site-packages (from fastai) (1.5.43)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2022.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (0.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.6.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (65.4.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.9/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.9/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->fastai) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->fastai) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->fastai) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->fastai) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.9/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fastai transformers numpy pandas nltk statsmodels matplotlib scipy psutil torch spacy scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:15.594558Z",
     "iopub.status.busy": "2024-06-02T09:39:15.593965Z",
     "iopub.status.idle": "2024-06-02T09:39:18.546395Z",
     "shell.execute_reply": "2024-06-02T09:39:18.545021Z",
     "shell.execute_reply.started": "2024-06-02T09:39:15.594511Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 2.7.15\n",
      "transformers version : 4.41.2\n",
      "1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pathlib import Path \n",
    "import random \n",
    "import os\n",
    "import nltk\n",
    "import math\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from matplotlib import dates\n",
    "from datetime import datetime\n",
    "import re\n",
    "import calendar\n",
    "import json\n",
    "from functools import partial\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from psutil import virtual_memory\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callback.all import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import AdamW\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# spacy\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "#scipy\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:19.471811Z",
     "iopub.status.busy": "2024-06-02T09:39:19.470927Z",
     "iopub.status.idle": "2024-06-02T09:39:19.615360Z",
     "shell.execute_reply": "2024-06-02T09:39:19.613913Z",
     "shell.execute_reply.started": "2024-06-02T09:39:19.471769Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  2 09:39:19 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:E8:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    40W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Your runtime has 810.2 gigabytes of available RAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Please enable gpu ')\n",
    "else:\n",
    "    print(gpu_info)\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Transformer models?\n",
    "\n",
    "TL DR: SOTA!\n",
    "\n",
    "The Transformer from <a href=\"https://arxiv.org/pdf/1706.03762.pdf\">“Attention is All You Need”</a>\n",
    " has been on a lot of people’s minds over the last year. Besides producing major improvements in translation quality, it provides a new architecture for many other NLP tasks. \n",
    "\n",
    "An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\n",
    "\n",
    "Transformers are also being used for image problems. Check out  <a href=\"https://arxiv.org/pdf/2010.11929.pdf\">“An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main transformers classes\n",
    "In transformers, each model architecture is associated with 3 main types of classes:\n",
    "\n",
    "A model class to load/store a particular pre-train model.\n",
    "A tokenizer class to pre-process the data and make it compatible with a particular model.\n",
    "A configuration class to load/store the configuration of a particular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:23.814379Z",
     "iopub.status.busy": "2024-06-02T09:39:23.813739Z",
     "iopub.status.idle": "2024-06-02T09:39:23.819444Z",
     "shell.execute_reply": "2024-06-02T09:39:23.818829Z",
     "shell.execute_reply.started": "2024-06-02T09:39:23.814345Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#main transformers class \n",
    "#https://huggingface.co/transformers/pretrained_models.html#pretrained-models\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig),\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:28.877887Z",
     "iopub.status.busy": "2024-06-02T09:39:28.877391Z",
     "iopub.status.idle": "2024-06-02T09:39:31.916652Z",
     "shell.execute_reply": "2024-06-02T09:39:31.915130Z",
     "shell.execute_reply.started": "2024-06-02T09:39:28.877849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn \n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:33.130403Z",
     "iopub.status.busy": "2024-06-02T09:39:33.129429Z",
     "iopub.status.idle": "2024-06-02T09:39:33.140422Z",
     "shell.execute_reply": "2024-06-02T09:39:33.139529Z",
     "shell.execute_reply.started": "2024-06-02T09:39:33.130333Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "### seed value for model reproducability ###\n",
    "seed = 1337\n",
    "\n",
    "### precision for ###\n",
    "use_fp16 = False\n",
    "\n",
    "### batch size ###\n",
    "\n",
    "bs = 16\n",
    "\n",
    "### Choose model ###\n",
    "\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-cased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
    "\n",
    "### text variables ###\n",
    "text_column = \"full_text\"\n",
    "target_col = \"score\"\n",
    "\n",
    "\n",
    "### Transformer Hyperparameters ###\n",
    "\n",
    "hidden_dropout_prob = 0.01\n",
    "initializer_range = 0.2\n",
    "layer_norm_eps = 1e-05\n",
    "attention_probs_dropout_prob = 0.1\n",
    "learning_wd = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:37.254013Z",
     "iopub.status.busy": "2024-06-02T09:39:37.253439Z",
     "iopub.status.idle": "2024-06-02T09:39:37.274478Z",
     "shell.execute_reply": "2024-06-02T09:39:37.273666Z",
     "shell.execute_reply.started": "2024-06-02T09:39:37.253975Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def my_auc(inp, targ):\n",
    "    \"Simple wrapper around scikit's roc_auc_score function for regression problems\"\n",
    "    inp,targ = flatten_check(inp,targ)\n",
    "    return roc_auc_score(targ.cpu().numpy(), inp.cpu().numpy())\n",
    "\n",
    "def setup_learner(databunch,initial=True,layer=1,model=None,path=None):\n",
    "    \"\"\"\n",
    "    Setup learner instance and optimizer\n",
    "    \"\"\"\n",
    "    \n",
    "    if not initial:\n",
    "        learner = load_learner(path,model)\n",
    "        learner.data = databunch\n",
    "    else:\n",
    "        CustomAdamW = partial(AdamW, correct_bias=False,weight_decay=0.1)\n",
    "        learner = Learner(databunch, \n",
    "                          custom_transformer_model, \n",
    "                          opt_func = CustomAdamW,\n",
    "                          metrics=[kappa,accuracy,error_rate])\n",
    "\n",
    "    ### Show graph of learner stats and metrics after each epoch ###\n",
    "    learner.callbacks.append(ShowGraph(learner))\n",
    "    \n",
    "    # Put learn in FP16 precision mode. --> Seems to not working\n",
    "    if use_fp16: \n",
    "        learner = learner.to_fp16()\n",
    "        \n",
    "        \n",
    "    # For DistilBERT\n",
    "    # list_layers = [learner.model.transformer.distilbert.embeddings,\n",
    "    #                learner.model.transformer.distilbert.transformer.layer[0],\n",
    "    #                learner.model.transformer.distilbert.transformer.layer[1],\n",
    "    #                learner.model.transformer.distilbert.transformer.layer[2],\n",
    "    #                learner.model.transformer.distilbert.transformer.layer[3],\n",
    "    #                learner.model.transformer.distilbert.transformer.layer[4],\n",
    "    #                learner.model.transformer.distilbert.transformer.layer[5],\n",
    "    #                learner.model.transformer.pre_classifier]\n",
    "\n",
    "    # For xlnet-base-cased\n",
    "    # list_layers = [learner.model.transformer.transformer.word_embedding,\n",
    "    #               learner.model.transformer.transformer.layer[0],\n",
    "    #               learner.model.transformer.transformer.layer[1],\n",
    "    #               learner.model.transformer.transformer.layer[2],\n",
    "    #               learner.model.transformer.transformer.layer[3],\n",
    "    #               learner.model.transformer.transformer.layer[4],\n",
    "    #               learner.model.transformer.transformer.layer[5],\n",
    "    #               learner.model.transformer.transformer.layer[6],\n",
    "    #               learner.model.transformer.transformer.layer[7],\n",
    "    #               learner.model.transformer.transformer.layer[8],\n",
    "    #               learner.model.transformer.transformer.layer[9],\n",
    "    #               learner.model.transformer.transformer.layer[10],\n",
    "    #               learner.model.transformer.transformer.layer[11],\n",
    "    #               learner.model.transformer.sequence_summary]\n",
    "\n",
    "    # For roberta-base\n",
    "    list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "                  learner.model.transformer.roberta.encoder.layer[0],\n",
    "                  learner.model.transformer.roberta.encoder.layer[1],\n",
    "                  learner.model.transformer.roberta.encoder.layer[2],\n",
    "                  learner.model.transformer.roberta.encoder.layer[3],\n",
    "                  learner.model.transformer.roberta.encoder.layer[4],\n",
    "                  learner.model.transformer.roberta.encoder.layer[5],\n",
    "                  learner.model.transformer.roberta.encoder.layer[6],\n",
    "                  learner.model.transformer.roberta.encoder.layer[7],\n",
    "                  learner.model.transformer.roberta.encoder.layer[8],\n",
    "                  learner.model.transformer.roberta.encoder.layer[9],\n",
    "                  learner.model.transformer.roberta.encoder.layer[10],\n",
    "                  learner.model.transformer.roberta.encoder.layer[11],\n",
    "                  learner.model.transformer.roberta.pooler]\n",
    "    learner.split(list_layers)\n",
    "    num_groups = len(learner.layer_groups)\n",
    "    seed_all(seed)\n",
    "    return learner,num_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Reproducibility\n",
    "Some important parts of the machine learning workflow where randomness appears:\n",
    "\n",
    "1. Data Preparation\n",
    "2. Pre-processing\n",
    "3. Cross-validation\n",
    "4. Weight initialization\n",
    "5. Hidden layers in the network\n",
    "6. Algorithms \n",
    "\n",
    "Setting the random seed across your pipeline you can achieve reproducibility. The “seed” is a starting point for the sequence and the guarantee is that if you start from the same seed you will get the same sequence of numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:40.773674Z",
     "iopub.status.busy": "2024-06-02T09:39:40.773120Z",
     "iopub.status.idle": "2024-06-02T09:39:40.784636Z",
     "shell.execute_reply": "2024-06-02T09:39:40.783639Z",
     "shell.execute_reply.started": "2024-06-02T09:39:40.773627Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    \"\"\"\n",
    "    Setting the random seed across the pipeline\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    random.seed(seed_value) \n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Summary of pre-process:\n",
    "We first tokenize and then numericalize our input\n",
    "\n",
    "processor = [TokenizeProcessor(tokenizer=tokenizer,...), NumericalizeProcessor(vocab=vocab,...)]\n",
    "\n",
    "Let's first analyse how we can integrate the transformers tokenizer within the TokenizeProcessor function.\n",
    "\n",
    "We can simply create a new class TransformersBaseTokenizer that inherits from BaseTokenizer and overwrite a new tokenizer function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tokenizer Function¶\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:45.599784Z",
     "iopub.status.busy": "2024-06-02T09:39:45.599254Z",
     "iopub.status.idle": "2024-06-02T09:39:45.612050Z",
     "shell.execute_reply": "2024-06-02T09:39:45.611300Z",
     "shell.execute_reply.started": "2024-06-02T09:39:45.599743Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer\n",
    "from typing import List\n",
    "\n",
    "class TransformersBaseTokenizer:\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type='bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.model_max_length  # Corrected property name\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t: str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and adds the special tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        # RoBERTa requires a space to start the input string.\n",
    "        if self.model_type in ['roberta']:\n",
    "            # Limit the sequence length to the model input size.\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "            tokens = [CLS] + tokens + [SEP]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "            if self.model_type in ['xlnet']:\n",
    "                tokens = tokens + [SEP] + [CLS]\n",
    "            else:\n",
    "                tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Huggingface documentation\n",
    "\n",
    "bert:       [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
    "\n",
    "distilbert: [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "xlnet:      padding + tokens + [SEP] + [CLS]\n",
    "\n",
    "Note: Padding is added by fastai when we create DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:48.938081Z",
     "iopub.status.busy": "2024-06-02T09:39:48.937014Z",
     "iopub.status.idle": "2024-06-02T09:39:48.954378Z",
     "shell.execute_reply": "2024-06-02T09:39:48.953730Z",
     "shell.execute_reply.started": "2024-06-02T09:39:48.938032Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "from typing import Collection, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "class TransformersVocab:\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return {'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.tokenizer = state['tokenizer']\n",
    "\n",
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        # attention_mask\n",
    "        # Mask to avoid performing attention on padding token indices.\n",
    "        # Mask values selected in ``[0, 1]``:\n",
    "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
    "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                  attention_mask = attention_mask)[0]   \n",
    "        return logits\n",
    "    \n",
    "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    the get_preds method does not yield the elements in order by default\n",
    "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
    "    \"\"\"\n",
    "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    return preds[reverse_sampler, :]\n",
    "\n",
    "def get_class_weights():\n",
    "    \"\"\"\n",
    "    Returns class weights for CrossEntropy Loss\n",
    "    \"\"\"\n",
    "    class_count_df = asap_train.groupby(target_col).count()\n",
    "    class_count_df\n",
    "    n_0, n_1, n_2, n_3, n_4, n_5 = class_count_df.iloc[:, 0]\n",
    "    w_0 = (n_0 + n_1 + n_2 + n_3 + n_4) / (6.0 * n_0)\n",
    "    w_1 = (n_0 + n_1 + n_2 + n_3 + n_4) / (6.0 * n_1)\n",
    "    w_2 = (n_0 + n_1 + n_2 + n_3 + n_4) / (6.0 * n_2)\n",
    "    w_3 = (n_0 + n_1 + n_2 + n_3 + n_4) / (6.0 * n_3)\n",
    "    w_4 = (n_0 + n_1 + n_2 + n_3 + n_4) / (6.0 * n_4)\n",
    "    w_5 = (n_0 + n_1 + n_2 + n_3 + n_4) / (6.0 * n_5)\n",
    "    # Important: Convert Weights To Float Tensor\n",
    "    class_weights = torch.FloatTensor([w_0, w_1, w_2, w_3, w_4, w_5]).cuda()\n",
    "    return class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:51.985383Z",
     "iopub.status.busy": "2024-06-02T09:39:51.984704Z",
     "iopub.status.idle": "2024-06-02T09:39:52.349163Z",
     "shell.execute_reply": "2024-06-02T09:39:52.348368Z",
     "shell.execute_reply.started": "2024-06-02T09:39:51.985338Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      essay_id,full_text,score\n",
      "59623  Most of the time, traffic causes a driver to be frustrated. What causes traffic? Vehicles. So why does everybody drive them? In small, well-populated suburbs, traffic is a major issue. With the dense population and the majority of those citizens driving vehicles, traffic is very easily created. Thus, making more citizens frustrated and creating road rage. Road rage also causes more accidents which causes more deaths. Making driving, a dangerous thing. Although, citizens still drive motorized vehicles. Most of the time it is to get to a certain place in a short amount of time, but if a dest...\n",
      "63249  Another benefit of FACS is mentioned later in the text. D'Alto mentions how FACS can help people reproduce and replicate certain emotions: he had his actors carefully reproduce smiling and frowning as a way of creating these emotions on stage.\"\" Through studying the methods of FACS, people can learn to replicate emotions. This can prove to be helpful in classroom setting, because as mentioned in the text, \"\"empathy may happen because we unconsciously imitate another person's facial expressions.\"\" When one students see his friend feeling down, he can help his friend cope by empathizing with...\n",
      "80597  BEEP! BEEP! BEEP! Get up. Get dressed. Go to work. Go home, repeat. what if i told you you could do so much more... For instants, take a stroll. Have a wonderful view of clusterd streets and inhale the polluted air, causedsouly from car usage. \"\"The goal is to promote alternative tranportation an reduce smog,\"\" stated in an excerpt from \"\"car-free day is spinning a big hit in bogota,\"\" sixteenth paragraph. After only five days with minimun car usage the smog revaled greatly. Ruducing car usage will help not only help the united stated but the whole world as one. The affects of over using c...\n",
      "56995  The Electoral College is a non-democraic method of selectiong a president that will be by declaring the candidate who receives the most popular votes the winner. According the the \"\"In Defense of the Electoral College\"\" article,\"\" the Elecoral College method is not democraic in a modern sense.....it is the electors who elect the president not the people.\"\" So bascially we are voting for the electors and we keep our finger crossed that they vote for the president we want. It is unpractical that the people vote for the president they would like to govern their counrty and then the opposite p...\n",
      "36327  My first argument is that technology always seems to fail. When you get a new iPhone, sometimes not everything is right in the phone or something is messed up from the start. If we had driverless cars in the future, technology would be the key function to make the car work. What if the technology failed like what seems to happen many times to iPhone users. I think having driverless cars is putting too much belief and risk into technology. You can never say when a problem would quickly approach or is about to happen, it just happens. If a problem just happened in a driverless car when the d...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(\"/home/jovyan/AES/train.csv\", sep='\\t', encoding='ISO-8859-1')\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = df.sample(frac=1, random_state=1337)  # Added random_state for reproducibility\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:39:55.506656Z",
     "iopub.status.busy": "2024-06-02T09:39:55.506113Z",
     "iopub.status.idle": "2024-06-02T09:39:56.416584Z",
     "shell.execute_reply": "2024-06-02T09:39:56.415814Z",
     "shell.execute_reply.started": "2024-06-02T09:39:55.506612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['essay_id', 'full_text', 'score'], dtype='object')\n",
      "      essay_id  \\\n",
      "16305  f08691e   \n",
      "9520   8c7c4fd   \n",
      "13512  c6781db   \n",
      "11139  a43acca   \n",
      "8050   786b550   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     full_text  \\\n",
      "16305  Do you think that the Face on Mars is a natural landform, or do you think that it was created by aliens? The picture of the Face on Mars was captured on May 21, 2001, and a few days later it was shown to the public which got this whole thing started. Most of the people from NASA believed that it was just a natural landform, but conspiracy theorists believed the it was created by aliens on Mars. The MOC team snapped a picture ten times sharper to reveal a natural landform. It was just a huge rock formation which resembled a human face, and the defenders of the NASA budget wished there was a...   \n",
      "9520   I was very excited about my first trip to the West Coast (California) that I took last summer. It was a place Ive always fantazized over because of its variety of beauty from the surfing beaches to the skiing mountains to the north. When I first landed in LA, I expected some hustle and bustle of the city like Miami, but it was overwhelming to see the smog and traffic that polluted many peoples views of California, along with the air. Unfortunately, this is the case in many car intensive cities across the globe where limiting car usage would go a great deal farther than people actually know...   \n",
      "13512  In the story Cowboy who Road the Waves i have to support why people would want to do his job. There are many reasons. Who would like a job that you got to see the world and travel. I would like to see the world. whaty about you?\\n\\nIn 1947 the world wars finaly ended WW1 and WW2 had a spand of 30 years. There was alot of mess to clean up and you had to be a certain person to do it. The see cowboys where just the right people. Luke said in the story that it was a fun job. But also hard. You got to see the world and do many activitys. You had lots of free time. But it was very dangerous he e...   \n",
      "11139  We can all be a superhero. Saving the world from smog. All you have to do is get rid of your car. Sounds impossible, but there are many advantages of limiting car usage. Once you have found another way to go about your day without a car, you might see that your life will improve, along with the Earth.\\n\\nIn Vauban, Germany there are many participators, \"70 percent of... families do not own cars, and 57 percent sold a car to move [there]\"(source 1). With the statisics of the greenhouse gas emissions in Europe and United States caused by passenger cars are so shocking, you can see why it is ...   \n",
      "8050   In the article \"Unmasking the Face on Mars\" a NASA air carft Viking 1 discovered a landformation that looked like a face but scientists proved that it's a mesa. Shadows from Marses clouds or from the atmoshpere could've formed the human like shadow. Theorists are saying that there is life on mars but don't have enough evidence from the article to prove so. NASA is wishing that there was evidence that there was life forms for the sake of their budget. These are some reasons that the conspiracy theorists are wrong.\\n\\nWhen the Viking 1 took the photo of the mesa the maritian skies could've b...   \n",
      "\n",
      "       score  \n",
      "16305      4  \n",
      "9520       5  \n",
      "13512      2  \n",
      "11139      4  \n",
      "8050       5  \n",
      "[3    36.285896\n",
      "2    27.289536\n",
      "4    22.684463\n",
      "1     7.234067\n",
      "5     5.604669\n",
      "6     0.901369\n",
      "Name: score, dtype: float64]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/4AAAInCAYAAAAh2oKeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAACOkUlEQVR4nOzdeXiU5fX/8c/MJJN9spNA2LdAILKILAoEWdSyqKhYrUrdFVFba2u1ov2JW20r1CKiKF+tFm0bq6gI1pUICiiLyC6EPYTsyWSdySy/PyYzEjYhJJlk8n5dFxfmmTvPcyYOkznPfe5zG9xut1sAAAAAACAgGf0dAAAAAAAAaDok/gAAAAAABDASfwAAAAAAAhiJPwAAAAAAAYzEHwAAAACAAEbiDwAAAABAACPxBwAAAAAggJH4AwAAAAAQwEj8AQAAAAAIYCT+AAD8hHfeeUepqam+P+np6brgggt0ww036KWXXlJRUdFx3zNv3jylpqae0XWqq6s1b948rV279oy+70TXGjt2rO64444zOs9P+eCDD/Taa6+d8LHU1FTNmzevUa/X2FavXq0rrrhCAwcOVGpqqj799NOTjs3NzdX/+3//TxdffLHOOeccDR06VFOmTNGsWbOUm5vbjFEDAHD2gvwdAAAArcXTTz+t7t27y+FwqKioSOvXr9fLL7+s//u//9PcuXN1/vnn+8ZOmzZNo0aNOqPzV1dX6/nnn9fdd9+tYcOGnfb3NeRaDbF06VLt2rVLN95443GP/fvf/1ZycnKTx9BQbrdbv/71r9W1a1ctWLBAYWFh6tat2wnHHjlyRFOnTpXFYtFNN92kbt26qaKiQrt379by5ct18OBBtW/fvpmfAQAADUfiDwDAaerVq5fS09N9X1988cW68cYb9Ytf/EJ33323Pv74YyUkJEiSkpOTmzwRrq6uVlhYWLNc66cMHDjQr9f/Kfn5+SotLdX48eM1YsSIU479z3/+o5KSEmVmZqpTp06+4+PHj9edd94pl8vV1OH61NTUKCQkRAaDodmuCQAIPJT6AwBwFjp06KDf//73qqys1L/+9S/f8ROV369evVo33HCDhg0bpnPOOUdjxozRPffco+rqah06dMiXkD7//PO+ZQUPPvhgvfNt3bpV9957r8477zxNmDDhpNfy+uSTTzRlyhSlp6dr3Lhxev311+s97l3GcOjQoXrH165dq9TUVN+ygxtuuEErVqxQTk5OvWUPXicq9f/hhx80Y8YMnXfeeUpPT9dll12md99994TXWbp0qebOnauRI0dq8ODBuvHGG7Vnz55T//DrrFu3Tr/85S81aNAgDRgwQNdcc41WrFjhe3zevHkaPXq0JOmvf/2rUlNTNXbs2JOer7S0VEajUfHx8Sd83Gis//Fp06ZNuvPOOzVs2DClp6dr/PjxevLJJ88oRunH/xerVq3SQw89pOHDh2vAgAGy2+2SpGXLlunnP/+5Bg4cqEGDBumWW27Rtm3b6p3j4MGDuu+++zRy5Ej1799f559/vn75y19q+/btp/wZAgACGzP+AACcpYyMDJlMJq1bt+6kYw4dOqQ77rhDQ4YM0ZNPPimLxaK8vDytXLlStbW1ateunV555RXdeuutuuqqqzRt2jRJUlxcXL3z3HPPPZo4caKuueYaVVVVnTKu7du366mnntLdd9+thIQEffDBB3ryySdVW1urW2655Yye4x//+Ec98sgjOnjwoJ5//vmfHL9nzx5dc801io+P18MPP6zY2Fi9//77evDBB1VYWKjbbrut3vg5c+Zo8ODBevLJJ1VRUaG//vWvmjFjhpYtWyaTyXTS63zzzTe6+eab1bt3bz355JMym8166623dOedd2rOnDmaOHGipk2bpj59+ujuu+/WDTfcoMmTJ8tsNp/0nAMHDtTixYt1zz336MYbb9SgQYMUGRl5wrErV67UjBkz1L17dz344INq3769cnJy9NVXX51RjEf7wx/+oDFjxujPf/6zqqurFRQUpBdffFF/+9vfdMUVV2jGjBmqra3VokWLdN111ykzM1M9e/aUJN12221yuVz63e9+pw4dOqikpEQbN26U1Wr9yf9nAIDAReIPAMBZCg8PV2xsrPLz8086ZuvWrbLZbHrggQfUp08f3/EpU6b4/rtfv36SPMsETlY6f/nll+vee+89rbjy8/O1ZMkS3/UyMjJUXFysF154Qb/4xS8UFhZ2WueRpJ49e8pischsNp9WWf/zzz+v2tpavf7667718BkZGbJarZo/f76uueYaRUVF1Tv/X//6V9/XRqNRv/71r7V58+ZTXu/ZZ5+VxWLRG2+8oYiICEnShRdeqMsvv1zPPPOMfvaznyk5OVkOh0OS1L59+5+Mf8qUKVq3bp0yMzO1atUqGQwGde/eXaNGjdINN9ygjh07+sbOnj1b7du3V2ZmpkJCQnzHr7zyyjOK8ehS/hEjRmj27Nm+r3NzczVv3jxdf/31mjVrlu/4+eefr4svvljPP/+8/va3v6mkpER79+7VH/7wB1122WW+cRdddNEpny8AIPBR6g8AQCNwu92nfLxv374KDg7WI488onfffVcHDx5s0HXOJInr1atXvZsMkjR58mRVVFRo69atDbr+6VqzZo1GjBhxXBO8qVOnqrq6Whs3bqx3/NjSe+8ygsOHD5/0GlVVVdq0aZMuvvhiX0ItSSaTSZdeeqmOHDly2ssFjmYwGDR79mx9+umn+uMf/6grrrhCDodDr732miZPnqxvvvlGkrR3714dOHBAV111Vb2k/2xjPPb/8apVq+RwOHTZZZfJ4XD4/oSEhOi8887zxRMTE6POnTtr0aJFevXVV7Vt27Zm7UcAAGi5mPEHAOAsVVVVqbS0VL179z7pmM6dO+u1117TK6+8otmzZ6uqqkqdOnXSDTfcoF/+8penfa127dqd9lhvo8ETHSstLT3t8zREaWmpEhMTjzvujf/Y68fExNT72luKX1NTc9JrWK1Wud3uM7rOmUhJSdEvfvEL39fLli3T/fffrz//+c96++23VVxcLElKSkpq1BiPHVtYWChJuuqqq054DW/PAYPBoNdee03z58/XK6+8oj/96U+KiYnRlClT9Otf//qkyxUAAIGPxB8AgLO0YsUKOZ1ODR069JTjhgwZoiFDhsjpdGrLli1644039NRTTykhIUGTJk1q9Li8CeOJjnkTbe9MtbeBnFdJSclZXTsmJkYFBQXHHfcuh4iNjT2r80uSxWKR0Whs8ut4TZw4UQsXLtSuXbsk/dh/IS8vr1FjPLaDv/fxv//97+rQocMpY0xJSdFTTz0lyVORsHz5cj3//POy2+31lg8AANoWSv0BADgLhw8f1p///GdFRUXpmmuuOa3vMZlMGjBggP74xz9Kkq/s/nRmuc/Erl27tGPHjnrHli5dqoiICF8/gZSUFEnSzp076437/PPPjzuf2Ww+7dhGjBihNWvWHJcUv/feewoLC2uU7f/Cw8M1YMAAffLJJ/Xicrlcev/995WcnKxu3bqd8XlP1quhsrJSubm5vpn6bt26qXPnzvrvf/973I2Txoxx5MiRCgoK0oEDB5Senn7CPyfSrVs33XXXXerdu/dx3f8BAG0LM/4AAJymXbt2yel0yuFwqLi4WOvWrdM777wjk8mk559//rgO/Ed76623tGbNGo0ZM0bt27eXzWbTf//7X0meJm2SFBkZqZSUFH322WcaMWKEoqOjFRsbW6+Z3Jlo166dZsyYobvvvluJiYl6//339dVXX+m3v/2tr7Ffenq6unXrpj//+c9yOp2yWCz69NNPtX79+uPO17t3b3388cd688031b9/fxkMhpMmnTNnztQXX3yh6dOna+bMmYqOjtYHH3ygFStW6He/+129xn5n4ze/+Y1uvvlmTZ8+XTfffLOCg4P15ptvateuXZozZ85xs+en48UXX9SGDRs0ceJE9enTR6GhoTp06JD++c9/qrS0VA888IBv7KOPPqoZM2bo6quv1o033qj27dsrNzdXK1eu1LPPPtsoMXbs2FH33nuv/va3v+ngwYMaPXq0LBaLCgsLtXnzZoWFhenee+/Vjh079Pjjj+uSSy5Rly5dFBwcrDVr1mjnzp26/fbbz/jnAAAIHCT+AACcpoceekiSFBwcLIvFoh49eui2227TtGnTTpn0S57mfl999ZXmzZungoIChYeHq3fv3lqwYIFGjhzpG/fkk0/qz3/+s2bMmCG73a6pU6fqT3/6U4Pi7du3r6644grNmzdP+/btU7t27fTQQw/pxhtv9I0xmUx68cUX9fjjj+uPf/yjzGazJk2apEcfffS4ZHH69OnatWuX5s6dq/Lycrnd7uMqBby6d++uf/3rX5ozZ45mz56tmpoa9ejRQ08//bSuuOKKBj2fExk6dKhee+01zZs3Tw899JBcLpf69OmjBQsW6MILL2zQOb0d8T/88EMtWrRI5eXlio6OVr9+/bRw4UJlZGT4xo4aNUr//Oc/NX/+fD3xxBOy2WxKTk6u16ywMWK844471KNHD73++uv68MMPZbfblZiYqP79++vaa6+V5OkN0LlzZ7355ps6cuSIJKlTp076/e9/rxtuuKFBPwsAQGAwuH+qDTEAAAAAAGi1WOMPAAAAAEAAI/EHAAAAACCAkfgDAAAAABDASPwBAAAAAAhgJP4AAAAAAAQwEn8AAAAAAAJYkL8DCBRDhgzx7akLAAAAAEBTKygokNls1rp16045jsS/kdhsNjmdTn+HAQAAAABoIxwOh9xu90+OI/FvJO3atZMkffbZZ36OBAAAAADQFowbN+60xrHGHwAAAACAAEbiDwAAAABAACPxBwAAAAAggJH4AwAAAAAQwEj8AQAAAAAIYCT+AAAAAAAEMBJ/AAAAAAACGIk/AAAAAAABjMQfAAAAAIAARuIPAAAAAEAAI/EHAAAAACCAkfgDAAAAABDASPwBAAAAAAhgJP4AAAAAAAQwEn8AAAAAAAIYiT8AAAAAAAGMxB8AAAAAgABG4g8AAAAAQAAj8QcAAAAAIICR+AMAAAAAEMBI/AEAOAW32x1Q1wEAAG1PkL8DAACgJTMYDFq1pVTWSkeTXcMSEaSR/WOa7PwAAKBtI/EHAOAnWCsdKi5vusQfAACgKVHqDwAAAABAACPxBwAAAAAggJH4AwAAAAAQwEj8AQAAAAAIYCT+AAAAAAAEMBJ/AAAAAAACGIk/AAAAAAABjMQfAAAAAIAARuIPAAAAAEAAI/EHAAAAACCAkfgDAAAAABDAWkzin5mZqUsvvVTp6ekaMWKE7rzzznqPZ2Vl6fLLL1d6eromTJigxYsXn/A8ixYt0tixY5Wenq4rr7xSa9euPW5MRUWFHn30UQ0bNkyDBg3SnXfeqZycnCZ5XgAAAAAA+FOLSPznzZunP/3pT5oyZYoWLVqk2bNnq127dr7HN27cqLvuuktpaWl6+eWXNXXqVD3xxBPKzMysd55FixZp7ty5uu6667Rw4UJ16dJFt912m3bu3Flv3P3336/PP/9cjzzyiObOnav8/HzddNNNqqmpaZbnCwAAAABAcwnydwDZ2dlasGCBFi5cqJEjR/qOT5gwwfff8+fPV1pamp566ilJ0vDhw5Wbm6vnnntOV155pYxGo+x2uxYsWKDp06frlltukSQNHTpUU6ZM0Ysvvqi5c+dKkjZt2qQVK1Zo4cKFysjIkCT17t1bEyZM0Lvvvqtrr722uZ46AAAAAABNzu8z/u+88446depUL+k/mt1u15o1azRp0qR6x6dMmaKCggJt27ZNkrRhwwaVl5dr8uTJvjEmk0kTJ05UVlaW3G63JM+SAYvFotGjR/vGdejQQYMHD1ZWVlZjPz0AAAAAAPzK74n/pk2b1Lt3b82fP18jRoxQ//79df3112v79u2SpAMHDqi2tlbdu3ev9309e/aU5KkYOPrvY8f16NFDlZWVysvL843r1q2bDAbDcefzngMAAAAAgEDh98S/oKBAq1at0gcffKDHHntM8+bNU3V1tW666SZZrVaVlZVJkiwWS73v837tfdxqtcpsNis0NLTeuOjoaElSaWmpb1xUVNRxcVgsFt+5AAAAAAAIFH5f4+92u1VVVaV58+apV69ekqR+/fpp3Lhx+ve//63BgwdL0nEz9F5HHz/RGG+J/0+NO9VxAAAAAABaK7/P+EdHRyshIcGX9EtSu3bt1L17d+3evds3Y3/sbLzVapX048y/xWKRzWaTzWY74TjveSwWi+/YseOOrSoAAAAAAKC183vi36NHjxMed7vdMhqN6ty5s4KDg7Vnz556j+/evbve93v/PnadfnZ2tiIiIpSUlOQbt3fvXl8lwNHnO1ksAAAAAAC0Vn5P/MeMGaPCwkL98MMPvmN5eXnas2ePUlNTZTabNXz4cC1fvrze9y1dulSJiYlKS0uTJA0ePFhRUVFatmyZb4zT6dTy5cuVkZHhK+PPyMiQ1WrVypUrfeNyc3O1YcMG3/Z+AAAAAAAECr+v8Z8wYYL69eune+65R7/61a9kNps1f/58xcXF6eqrr5YkzZw5U9dff71mzZqlKVOmaMOGDcrMzNTs2bNlNHruXZjNZs2YMUNz585VXFyc0tLSlJmZqYMHD2rOnDm+6w0YMEBjxozRww8/rAcffFCRkZF67rnnlJKSoqlTp/rlZwAAAAAAQFPxe+JvMpn08ssv66mnntKjjz4qh8Oh8847T88++6zCw8MlSYMGDdILL7ygOXPmaMmSJUpOTtasWbM0bdq0eue6+eab5Xa79cYbb6iwsFC9e/fWwoULlZqaWm/cs88+q2eeeUaPPfaYamtrNWzYMM2bN++4HQEAAAAAAGjtDO5jF7ujQcaNGydJ+uyzz/wcCQCgsS1bW6jickeTnT8uKkgThyU02fkBAEBgOt081O9r/AEAAAAAQNMh8QcAAAAAIICR+AMAAAAAEMBI/AEAAAAACGAk/gAAAAAABDASfwAAAAAAAhiJPwAAAAAAAYzEHwAAAACAAEbiDwAAAABAACPxBwAAAAAggJH4AwAAAAAQwEj8AQAAAAAIYCT+AAAAAAAEMBJ/AAAAAAACGIk/AAAAAAABjMQfAAAAAIAARuIPAAAAAEAAI/EHAAAAACCAkfgDAAAAABDASPwBAAAAAAhgJP4AAAAAAAQwEn8AAAAAAAIYiT8AAAAAAAGMxB8AAAAAgABG4g8AAAAAQAAj8QcAAAAAIICR+AMAAAAAEMBI/AEAAAAACGAk/gAAAAAABDASfwAAAAAAAhiJPwAAAAAAAYzEHwAAAACAAEbiDwAAAABAACPxBwAAAAAggJH4AwAAAAAQwEj8AQAAAAAIYCT+AAAAAAAEMBJ/AAAAAAACGIk/AAAAAAABjMQfAAAAAIAARuIPAAAAAEAAI/EHAAAAACCAkfgDAAAAABDASPwBAAAAAAhgJP4AAAAAAAQwEn8AAAAAAAIYiT8AAAAAAAGMxB8AAAAAgABG4g8AAAAAQAAj8QcAAAAAIICR+AMAAAAAEMBI/AEAAAAACGAk/gAAAAAABDASfwAAAAAAAhiJPwAAAAAAAYzEHwAAAACAAEbiDwAAAABAAPN74v/OO+8oNTX1uD9//etf643LysrS5ZdfrvT0dE2YMEGLFy8+4fkWLVqksWPHKj09XVdeeaXWrl173JiKigo9+uijGjZsmAYNGqQ777xTOTk5TfL8AAAAAADwpyB/B+D1yiuvKCoqyvd1UlKS7783btyou+66S5dddpkefPBBbdiwQU888YTMZrOmTZvmG7do0SLNnTtX9913n9LS0pSZmanbbrtNmZmZSk1N9Y27//77tXXrVj3yyCOKjIzU3//+d9100016//33FRoa2jxPGAAAAACAZtBiEv9+/fopLi7uhI/Nnz9faWlpeuqppyRJw4cPV25urp577jldeeWVMhqNstvtWrBggaZPn65bbrlFkjR06FBNmTJFL774oubOnStJ2rRpk1asWKGFCxcqIyNDktS7d29NmDBB7777rq699tpmeLYAAAAAADQPv5f6/xS73a41a9Zo0qRJ9Y5PmTJFBQUF2rZtmyRpw4YNKi8v1+TJk31jTCaTJk6cqKysLLndbkmeJQMWi0WjR4/2jevQoYMGDx6srKysZnhGAAAAAAA0nxaT+E+ePFl9+/bVuHHj9NJLL8npdEqSDhw4oNraWnXv3r3e+J49e0qSsrOz6/197LgePXqosrJSeXl5vnHdunWTwWA47nzecwAAAAAAECj8XuqfmJioe+65RwMGDJDBYNDnn3+uv/3tb8rLy9Ojjz6qsrIySZLFYqn3fd6vvY9brVaZzebj1uhHR0dLkkpLS5WcnCyr1Vqvl8DR5/OeCwAAAACAQOH3xH/UqFEaNWqU7+uRI0cqJCRE//jHP3TnnXf6jh87Q3+i4yca4y3x/6lxpzoOAAAAAEBr1WJK/Y/2s5/9TE6nU9u3b/fN2B87G2+1WiX9OPNvsVhks9lks9lOOM57HovF4jt27LhjqwoAAAAAAGjtWmTif7TOnTsrODhYe/bsqXd89+7dkjxr+I/++9h1+tnZ2YqIiPBtD9ijRw/t3bvXVwlw9Pm85wAAAAAAIFC0yMR/2bJlMplMSktLk9ls1vDhw7V8+fJ6Y5YuXarExESlpaVJkgYPHqyoqCgtW7bMN8bpdGr58uXKyMjwlfFnZGTIarVq5cqVvnG5ubnasGGDb3s/AAAAAAAChd/X+N9yyy0aPny4evfuLUn67LPP9J///EfTp09XYmKiJGnmzJm6/vrrNWvWLE2ZMkUbNmxQZmamZs+eLaPRc+/CbDZrxowZmjt3ruLi4pSWlqbMzEwdPHhQc+bM8V1vwIABGjNmjB5++GE9+OCDioyM1HPPPaeUlBRNnTq1+X8AAAAAAAA0Ib8n/t26ddPbb7+tI0eOyOVyqWvXrvrDH/6gG264wTdm0KBBeuGFFzRnzhwtWbJEycnJmjVrlqZNm1bvXDfffLPcbrfeeOMNFRYWqnfv3lq4cKFSU1PrjXv22Wf1zDPP6LHHHlNtba2GDRumefPmHbcjAAAAAAAArZ3BfexidzTIuHHjJHkqFgAAgWXZ2kIVlzua7PxxUUGaOCyhyc4PAAAC0+nmoS1yjT8AAAAAAGgcJP4AAAAAAAQwEn8AAAAAAAIYiT8AAAAAAAGMxB8AAAAAgABG4g8AAAAAQAAj8QcAAAAAIICR+AMAAAAAEMBI/AEAAAAACGAk/gAAAAAABDASfwAAAAAAAhiJPwAAAAAAAYzEH0CTcLvdAXENAAAAoLUL8ncAAAKTwWDQqi2lslY6muT8loggjewf0yTnBgAAAAIJiT+AJmOtdKi4vGkSfwAAAACnh1J/AAAAAAACGIk/AAAAAAABjMQfAAAAAIAARuIPAAAAAEAAI/EHAAAAACCAkfgDAAAAABDASPwBAAAAAAhgJP4AAAAAAAQwEn8AAAAAAAIYiT8AAAAAAAGMxB8AAAAAgABG4g8AAAAAQAAj8QcAAAAAIICR+AMAAAAAEMBI/AEAAAAACGAk/gAAAAAABDASfwAAAAAAAhiJPwAAAAAAAYzEHwAAAACAAEbiDwAAAABAACPxBwAAAAAggJH4AwAAAAAQwEj8AQAAAAAIYCT+AAAAAAAEMBJ/AAAAAAACGIk/AAAAAAABjMQfAAAAAIAARuIPAAAAAEAAI/EHAAAAACCAkfgDAAAAABDASPwBAAAAAAhgJP4AAAAAAAQwEn8AAAAAAAIYiT8AAAAAAAGMxB8AAAAAgABG4g8AAAAAQAAj8QcAAAAAIICR+AMAAAAAEMBI/AEAAAAACGAk/gAAAAAABDASfwAAAAAAAhiJPwAAAAAAAaxFJf6VlZUaPXq0UlNTtXnz5nqPZWVl6fLLL1d6eromTJigxYsXn/AcixYt0tixY5Wenq4rr7xSa9euPW5MRUWFHn30UQ0bNkyDBg3SnXfeqZycnCZ5TgAAAAAA+FOLSvxfeOEFOZ3O445v3LhRd911l9LS0vTyyy9r6tSpeuKJJ5SZmVlv3KJFizR37lxdd911Wrhwobp06aLbbrtNO3furDfu/vvv1+eff65HHnlEc+fOVX5+vm666SbV1NQ06fMDAAAAAKC5tZjEPzs7W2+++abuueee4x6bP3++0tLS9NRTT2n48OG66667dNVVV+m5556Ty+WSJNntdi1YsEDTp0/XLbfcohEjRugvf/mLOnbsqBdffNF3rk2bNmnFihV68sknNXnyZI0ZM0bPP/+8cnJy9O677zbb8wUAAAAAoDm0mMT/ySef1DXXXKNu3brVO26327VmzRpNmjSp3vEpU6aooKBA27ZtkyRt2LBB5eXlmjx5sm+MyWTSxIkTlZWVJbfbLcmzZMBisWj06NG+cR06dNDgwYOVlZXVVE8PAAAAAAC/aBGJ/0cffaQdO3Zo5syZxz124MAB1dbWqnv37vWO9+zZU5KnUuDov48d16NHD1VWViovL883rlu3bjIYDMedz3sOAAAAAAAChd8T/+rqav3pT3/Sb37zG0VGRh73eFlZmSTJYrHUO+792vu41WqV2WxWaGhovXHR0dGSpNLSUt+4qKio465jsVh85wIAAAAAIFD4PfFfsGCB4uPjdcUVV5xy3LEz9Cc6fqIx3hL/nxp3quMAAAAAALRWfk38c3Jy9H//93+69957VVFRIavVqqqqKklSVVWVKisrfTP2x87GW61WST/O/FssFtlsNtlsthOO857HYrH4jh077tiqAgAAAAAAWrsgf1780KFDqq2t1e23337cY9OnT9eAAQP0z3/+U8HBwdqzZ0+9hny7d++W5FnDf/Tf2dnZSktL843Lzs5WRESEkpKSfOO+/vprud3uejP8u3fv9p0DAAAAAIBA4dcZ/759++r111+v9+ehhx6SJD322GP64x//KLPZrOHDh2v58uX1vnfp0qVKTEz0JfmDBw9WVFSUli1b5hvjdDq1fPlyZWRk+JL8jIwMWa1WrVy50jcuNzdXGzZsUEZGRlM/ZQAAAAAAmpVfZ/wtFouGDRt2wsf69eunfv36SZJmzpyp66+/XrNmzdKUKVO0YcMGZWZmavbs2TIaPfcuzGazZsyYoblz5youLk5paWnKzMzUwYMHNWfOHN95BwwYoDFjxujhhx/Wgw8+qMjISD333HNKSUnR1KlTm/5JAwAAAADQjPya+J+uQYMG6YUXXtCcOXO0ZMkSJScna9asWZo2bVq9cTfffLPcbrfeeOMNFRYWqnfv3lq4cKFSU1PrjXv22Wf1zDPP6LHHHlNtba2GDRumefPmHbcjAAAAQHM4dglia70GAKBlMri9be9xVsaNGydJ+uyzz/wcCdByLFtbqOJyR5OcOy4qSBOHJTTJuYFjNeVrWeL1DI9VW0plrWya15klIkgj+8c0ybkBAP5zunloq5jxBwAACHTWSkeT3mACALRdfm3uBwAAAAAAmlaDE/+CgoLGjAMAAAAAADSBBif+F154oX7zm99o/fr1jRkPAAAAAABoRA1O/O+8806tW7dO119/vS677DJlZmaqpqamMWMDAAAAAABnqcGJ/913360vvvhCzz77rCIjI/XII48oIyNDzzzzjA4cONCYMQIAAAAAgAY6q+Z+JpNJEydO1OLFi7VkyRJddNFF+te//qVLLrlEd9xxh1auXNlYcQIAAAAAgAZotK7+qampGj16tHr16iWXy6XVq1fr9ttv1xVXXKG9e/c21mUAAAAAAMAZOOvEv7i4WC+99JLGjRune++9VyaTSXPnztX69es1f/58VVZW6qGHHmqMWAEAAAAAwBkKaug3btq0SYsXL9ZHH30kt9utiRMnavr06erXr59vzNixY2UymTRz5sxGCRYAAAAAAJyZBif+P//5z5WQkKDbb79d1157reLj4084rmPHjho0aFCDAwQAAAAAAA3X4MT/mWee0cSJExUcHHzKcT169NAbb7zR0MsAAAAAAICz0ODE/7LLLmvMOAAAAAAAQBNocHO/hQsX6vHHHz/hY48//rgWLVrU4KAAAAAAAEDjaHDiv2TJEvXq1euEj/Xp00dLlixp6KkBAAAAAEAjaXDif/jwYXXt2vWEj3Xu3FmHDh1q6KkBAAAAAEAjaXDiHxQUpOLi4hM+VlRUJIPB0OCgAAAAAABA42hw4t+/f3/95z//OeFj//nPf9S/f/8GBwUAAAAAABpHg7v633zzzbrjjjt0ww036Nprr1VSUpLy8vL01ltvad26dVq4cGFjxgkAAAAAABqgwYn/6NGjNXv2bD3zzDP6zW9+I4PBILfbraioKD3++OMaNWpUY8YJAAAAAAAaoMGJvyRNmzZNkyZN0saNG1VcXKy4uDgNGjRI4eHhjRUfAAAAAAA4C2eV+EtSeHi4LrjggsaIBQAAAAAANLKzSvzdbrc2b96snJwc2Wy24x6//PLLz+b0AAAAAADgLDU48d+7d69mzJih/fv3y+12H/e4wWAg8QcAAAAAwM8anPjPnj1bdrtdc+fOVWpqqsxmc2PGBQAAAAAAGkGDE//vv/9ejz/+uC655JLGjAcAAAAAADQiY0O/MTw8XJGRkY0ZCwAAAAAAaGQNTvyvuOIKLV26tDFjAQAAAAAAjazBpf69e/fWhx9+qDvvvFNjx45VTEzMcWMuuuiis4kNAAAAAACcpQYn/vfff78k6dChQ1qxYsVxjxsMBm3fvr3BgQEAAAAAgLPX4MT/9ddfb8w4AAAAAABAE2hw4j906NDGjAMAAAAAADSBBif+XuXl5fruu+9UUlKijIwMRUdHN0ZcAAAAAACgEZxV4j9//ny9/PLLqqmpkcFg0Ntvv63o6Gj98pe/1AUXXKDbb7+9seIEAAAAAAAN0ODt/BYvXqz58+frqquu0ksvvSS32+177MILLzxhwz8AAAAAANC8Gjzjv3jxYt1444164IEH5HQ66z3WpUsX7d+//6yDAwAAAAAAZ6fBM/4HDx7UqFGjTvhYRESErFZrg4MCAAAAAACNo8GJf1RUlAoLC0/4WE5OjuLj4xscFAAAAAAAaBwNTvxHjBihV155RVVVVb5jBoNBDodDb731lkaOHNkoAQIAAAAAgIZr8Br/e++9V1dddZUmTZqk8ePHy2Aw6J///Ke2b9+uw4cP629/+1sjhgkAAAAAABqiwTP+Xbp00VtvvaXu3bvrrbfektvt1nvvvafY2Fi9+eab6tChQ2PGCQAAAAAAGqDBM/6S1LNnTy1atEh2u10lJSWKjo5WaGhoY8UGAAAAAADO0lkl/l5ms1lJSUmNcSoAAAAAANCIGpz4P//886d83GAwaObMmQ09PQAAAAAAaAQk/gAAAAAABLAGJ/47duw47lhpaak+/fRT/eMf/9DChQvPKjAAAAAAAHD2GtzV/0RiYmJ01VVXacqUKXriiSca89QAAAAAAKABGjXx90pPT9fq1aub4tQAAAAAAOAMNEniv3PnToWHhzfFqQEAAAAAwBlo8Br/JUuWHHfMbrdr586d+u9//6tLL730bOICAAAAAACNoMGJ/4MPPnjC4yEhIbr00kv1wAMPNDgoAAAAAADQOBqc+H/22WfHHQsJCVFCQsJZBQQAAAAAABpPgxP/lJSUxowDAAAAAAA0gSZp7gcAAAAAAFqGBs/49+nTRwaD4bTGGgwGbdu2raGXAgAAAAAADdTgxH/mzJl69913VVlZqbFjxyohIUEFBQX64osvFBERoSuuuKIx4wQAAAAAAA3Q4MQ/IiJCCQkJ+uCDDxQREeE7XlFRoZtuukmhoaG69dZbGyVIAAAAAADQMA1e4//mm2/q1ltvrZf0S1JkZKRuvfVWvfnmm6d1npUrV+r666/X8OHD1b9/f40bN05PP/20ysvL643LysrS5ZdfrvT0dE2YMEGLFy8+4fkWLVqksWPHKj09XVdeeaXWrl173JiKigo9+uijGjZsmAYNGqQ777xTOTk5p/nMAQAAAABoPRqc+Ofl5clkMp3wMZPJpMLCwtM6T1lZmQYNGqTHH39cixYt0k033aQlS5boV7/6lW/Mxo0bdddddyktLU0vv/yypk6dqieeeEKZmZn1zrVo0SLNnTtX1113nRYuXKguXbrotttu086dO+uNu//++/X555/rkUce0dy5c5Wfn6+bbrpJNTU1Z/hTAAAAAACgZWtwqX+PHj302muvafTo0QoODvYdt9vtevXVV9W9e/fTOs/kyZM1efJk39fDhg2T2WzWI488ory8PCUlJWn+/PlKS0vTU089JUkaPny4cnNz9dxzz+nKK6+U0WiU3W7XggULNH36dN1yyy2SpKFDh2rKlCl68cUXNXfuXEnSpk2btGLFCi1cuFAZGRmSpN69e2vChAl69913de211zb0RwIAAAAAQIvT4Bn/X//619qwYYPGjx+vJ554Qi+99JKeeOIJTZgwQd99951+/etfNziomJgYSZLD4ZDdbteaNWs0adKkemOmTJmigoIC324BGzZsUHl5eb2bCCaTSRMnTlRWVpbcbrckz5IBi8Wi0aNH+8Z16NBBgwcPVlZWVoNjBgAAAACgJWpw4j9mzBi98sorSkpK0ptvvqm5c+dq8eLFSk5O1ssvv6wxY8ac0fmcTqdsNpu2bt2q+fPn68ILL1RKSooOHDig2tra4yoIevbsKUnKzs6u9/ex43r06KHKykrl5eX5xnXr1u24rQh79uzpOwcAAAAAAIGiwaX+kjRixAiNGDFC1dXVslqtslgsCgsLa9C5LrzwQl9yPmrUKM2ZM0eSpweAJFkslnrjvV97H7darTKbzQoNDa03Ljo6WpJUWlqq5ORkWa1WRUVFHXd9i8XiOxcAAAAAAIHirBJ/L+/s+dFr/c/UwoULVVVVpd27d+uFF17QnXfeqVdfffW4a5zs2icb4y3x/6lxpzoOAAAAAEBr1eBSf0las2aNfv7zn2vw4MG68MILfd3zH3vsMX388cdndK4+ffpo8ODBuvrqq/X8889r7dq1+uSTT3wz9sfOxlutVkk/zvxbLBbZbDbZbLYTjvOex2Kx+I4dO+7YqgIAAAAAAFq7Bif+q1ev1i233CKbzaabb75ZLpfL91hsbKzeeeedBgfVt29fmUwmHThwQJ07d1ZwcLD27NlTb8zu3bsledbwH/33sev0s7OzFRERoaSkJN+4vXv3+ioBjj6f9xwAAAAAAASKBif+f//73zV69GgtWbLkuA7+ffr00Y4dOxoc1MaNG+V0OtWxY0eZzWYNHz5cy5cvrzdm6dKlSkxMVFpamiRp8ODBioqK0rJly3xjnE6nli9froyMDF8Zf0ZGhqxWq1auXOkbl5ubqw0bNvi29wMAAAAAIFA0eI3/9u3b9dxzz0k6fm18XFycioqKTus8d999t/r376/U1FSFhoZqx44deuWVV5Samqrx48dLkmbOnKnrr79es2bN0pQpU7RhwwZlZmZq9uzZMho99y7MZrNmzJihuXPnKi4uTmlpacrMzNTBgwd9jQIlacCAARozZowefvhhPfjgg4qMjNRzzz2nlJQUTZ06taE/DgAAAAAAWqQGJ/4mk0m1tbUnfKyoqEgRERGndZ5zzjlHy5Yt08KFC+V2u5WSkqKrr75at9xyi8xmsyRp0KBBeuGFFzRnzhwtWbJEycnJmjVrlqZNm1bvXDfffLPcbrfeeOMNFRYWqnfv3lq4cKFSU1PrjXv22Wf1zDPP6LHHHlNtba2GDRumefPmHbcjAAAAAAAArV2DE//09HS9//77vln5o/3vf//TwIEDT+s8t99+u26//fafHJeRkfGTpfgGg0G33nqrbr311lOOi4yM1OOPP67HH3/8tGIEAAAAAKC1anDif/vtt+uWW27RzJkzdfnll8tgMGjTpk3673//q//973/6xz/+0ZhxAgAAAACABmhw4n/++efrT3/6k5566il99tlnkqTZs2fLYrHo6aef1pAhQxotSAAAAAAA0DANSvydTqcOHDigCy+8UBdffLE2btyowsJCxcbGavDgwQoPD2/sOAEAAAAAQAM0KPF3u92aNGmSFixYoIyMDI0YMaKx4wIAAAAAAI3A2JBvCgoKUkJCgtxud2PHAwAAAAAAGlGDEn9JmjRpkpYsWdKIoQAAAAAAgMbW4OZ+ffr00bJlyzR9+nRddNFFSkxMlMFgqDfmoosuOusAAQAAAABAwzU48f/9738vScrLy9M333xz3OMGg0Hbt29veGQAAAAAAOCsnVHi/+c//1nTp09XcnKyXn/9dUmeDv8mk6lJggMAAAAAAGfnjBL/V199VZdccomSk5M1dOhQOZ1O9e/fX2+//bb69evXVDECAAAAAIAGOqPmfifq4k9nfwAAAAAAWq4Gd/UHAAAAAAAtH4k/AAAAAAAB7Iy7+u/Zs8fXzM/pdPqOnQjr/gEAAAAA8K8zTvwfeuih44498MAD9b52u91s5wcAAAAAQAtwRon/008/3VRxAAAAAACAJnBGif/UqVObKg4AAAAAANAEaO4HAAAAAEAAI/EHAAAAACCAkfgDAAAAABDASPwBAAAAAAhgJP4AAAAAAAQwEn8AAAAAAALYGW3nBwBAW2V3uFRe5VRljedPVY1L8ZZgdU0O9XdoAAAAp0TiDwDAT9iTW62Pvi2W03X8Yw6XWz07hDV/UAAAAKeJxB8AgFPIKbTpk/Ulcrqk0GCjIsNMigg1yumWDhXY9M12q8wmgzonMfMPAABaJhJ/AABOosbu0pOL98nucCsxOljjB8fKaDRIktxut77ZUa7dh6v11dYyBQUZ1CE+xM8RAwAAHI/mfgAAnMQL7x/S3iM1CgsxamR6tC/plySDwaDz+kSpS7sQudzSl9+XqqDU7sdoAQAATozEHwCAE/jfuiJ9sr5ERoN08ZA4hYeYjhtjNBg0ol+0OsSb5XRJKzaVqtrm9EO0AAAAJ0fiDwDAMfbkVuuF93IkSTdMSFanxJOX8JuMBo1Kj1FsVJDsDrd2HKxqrjABAABOC4k/AADHeGXZYdkdbp2XGqWrM9r95Pggk0HndIuQJO3KqVat4wTt/wEAAPyExB8AgKMcyK/Rxt0VMhqkmZd1rLeu/1RSEkJkCTep1uHW7pzqJo4SAADg9JH4AwBwlKVrCiVJQ/tYlBRrPu3vMxgMSuvimfXffrBKTpe7SeIDAAA4UyT+AADUqbI59emGEknSlBEJZ/z9XZNDFWY2qtrm0v68msYODwAAoEFI/AEAqPP5hhJV21zqmBiigT0iz/j7TUaDUjuFS5K27a+U282sPwAA8D8SfwAAJLndbr1fV+Y/eXj8aa/tP1avlDAFmQwqq3TqcJG9MUMEAABoEBJ/AAAkbdpToYP5NoWZjRo/OK7B5zEHG9UrJUySZ9YfAADA30j8AQCQtHR1kSRp7KBYRYSazupcfTqFy2iQ8ktrVVhW2xjhAQAANBiJPwCgzcsvtWv1tjJJDWvqd6zwUJO6JIVKkvbksrUfAADwLxJ/AECbt2xtkVxuaUD3SF/Cfra85zlUYKPJHwAA8CsSfwBAm+ZyufXJ+mJJ0uQR8Y123uQ4s4JNBlXbXZT7AwAAvyLxBwC0aT8cqlJxuUNhIUYN62NptPOajAalJIZIkg4W2BrtvAAAAGeKxB8A0Kat2W6VJJ3XO0rBQY37a7FzXeJ/IL+Gcn8AAOA3JP4AgDbN29RveFp0o5+7fXyITEapssalknJHo58fAADgdJD4AwDarMOFNh3It8lklIakRjX6+YNMBnWIr5v1p9wfAAD4CYk/AKDN8pb59+8WqaiwoCa5Rqd2dev882ua5PwAAAA/hcQfANBmrd7uKfMf0bfxmvodq2NCiIwGyVrlVFkF5f4AAKD5kfgDANoka6VD2/ZVSmqa9f1ewUFGJceZJUkHCpj1BwAAzY/EHwDQJn2z0yqXW+qWHKqkWHOTXqtzu1BJ0sF81vkDAIDmR+IPAGiT1mzzrO9vytl+r5SEEBkMUkmFQ+XVlPsDAIDmReIPAGhz7LUurd9VLkka3oTr+71CzUa1i/FUFTDrDwAAmhuJPwCgzfkuu0I1dpfiLcHqlRLWLNfslOjp7p9TSOIPAACaF4k/AKDNWVPXzX94X4sMBkOzXLNDvGfGv7CsVg6nu1muCQAAIJH4AwDaGJfLrbXb69b3N0OZv1dkmEkRoUa53FJ+qb3ZrgsAAEDiDwBoU/YcqVZxuUNhZqPO6RHZbNc1GAy+bf2OFJP4AwCA5kPiDwBoUzZlV0iS0rtFyBzUvL8Gk2M96/xJ/AEAQHMi8QcAtCnexL85Z/u9vDP+JRUO1dhdzX59AADQNvk98V++fLnuuusuZWRkaODAgZoyZYrefPNNuVz1PxBlZWXp8ssvV3p6uiZMmKDFixef8HyLFi3S2LFjlZ6eriuvvFJr1649bkxFRYUeffRRDRs2TIMGDdKdd96pnJycJnl+AICWw+F0a8veSknSAD8k/qFmo2IigyRJR0qY9QcAAM3D74n/q6++KrPZrAceeEAvvviixo8fryeffFJ/+ctffGM2btyou+66S2lpaXr55Zc1depUPfHEE8rMzKx3rkWLFmnu3Lm67rrrtHDhQnXp0kW33Xabdu7cWW/c/fffr88//1yPPPKI5s6dq/z8fN10002qqalplucMAPCPXYeqVG13KTLMpO7JzbON37FY5w8AAJpbkL8DePHFFxUXF+f7evjw4aqqqtLixYt13333yWw2a/78+UpLS9NTTz3lG5Obm6vnnntOV155pYxGo+x2uxYsWKDp06frlltukSQNHTpUU6ZM0Ysvvqi5c+dKkjZt2qQVK1Zo4cKFysjIkCT17t1bEyZM0Lvvvqtrr722mX8CAIDm8t0eT5n/gO6RMhqbZxu/YyXHmrXjQJWOFNv8cn0AAND2+H3G/+ik36tv376y2WwqLS2V3W7XmjVrNGnSpHpjpkyZooKCAm3btk2StGHDBpWXl2vy5Mm+MSaTSRMnTlRWVpbcbs+eyVlZWbJYLBo9erRvXIcOHTR48GBlZWU1xVMEALQQ39et7/dHmb9Xu5hgGQxSZY1L5dUOv8UBAADaDr8n/ieyfv16xcTEKD4+XgcOHFBtba26d+9eb0zPnj0lSdnZ2fX+PnZcjx49VFlZqby8PN+4bt26yWCoP9PTs2dP3zkAAIHHXuvStv3+W9/vFRxkVEJ0sCTK/QEAQPNocYn/5s2b9c477+iXv/ylTCaTysrKJEkWi6XeOO/X3setVqvMZrNCQ0PrjYuOjpYklZaW+sZFRUUdd12LxeI7FwAg8Ow4WCW7w63YqCB1SgzxayztY1nnDwAAmk+LSvwLCgp07733Kj09Xbfddlu9x46doT/R8RON8Zb4/9S4Ux0HALR+32X/uL7f3+/3SXUN/vJK7L7fUwAAAE2lxST+5eXluu222xQaGqoFCxYoONhTBumdsT92Nt5qtUr6cebfYrHIZrPJZrOdcJz3PBaLxXfs2HHHVhUAAALHpuxySdJAP5b5eyVYghVkMshW61ZJBev8AQBA02oRib/NZtOMGTNUWFioV155RbGxsb7HOnfurODgYO3Zs6fe9+zevVuSZw3/0X8fu04/OztbERERSkpK8o3bu3fvcTMsu3fv9p0DABBYqm1O7TxYJcm/6/u9jEaDkmJZ5w8AAJqH3xN/h8OhX/3qV9qxY4deeeUVpaSk1HvcbDZr+PDhWr58eb3jS5cuVWJiotLS0iRJgwcPVlRUlJYtW+Yb43Q6tXz5cmVkZPjKOjMyMmS1WrVy5UrfuNzcXG3YsMG3vR8AILBs3Vcpp0tKijUrOc6/6/u9klnnDwAAmkmQvwOYPXu2vvjiC/3ud79TTU2NvvvuO99jPXv2VGRkpGbOnKnrr79es2bN0pQpU7RhwwZlZmZq9uzZMho99y7MZrNmzJihuXPnKi4uTmlpacrMzNTBgwc1Z84c3zkHDBigMWPG6OGHH9aDDz6oyMhIPffcc0pJSdHUqVOb++kDOIrb7VZ5tVN5JXaFh5jUId7s97XYCAyb9vh/G79jeW5AVCi/1C6ni3X+AACg6fg98V+1apUk6S9/+ctxj73++usaNmyYBg0apBdeeEFz5szRkiVLlJycrFmzZmnatGn1xt98881yu9164403VFhYqN69e2vhwoVKTU2tN+7ZZ5/VM888o8cee0y1tbUaNmyY5s2bd9yOAACantvtVk6RXTkFNuUW21RZ4/I91j7OrPP6RCkqzO9vVWjlNh3V2K+liI4wyRxkkN3hVkFprb/DAQAAAczvn6Y///zz0xqXkZHxk6X4BoNBt956q2699dZTjouMjNTjjz+uxx9//LTjBNA0Nu+t1Oa9lb6vjQYp3hKsovJa5Rbb9eGaIqV3i1TfzuEyGpn9x5krr3Zo9+FqSS1rxt9gMKhdjFmHCm06XGT76W8AAABoIL8n/gDaruzD1b6kv2eHMHVMDFFSrFlBJoOsVQ59s6NceSV2fZddof15NRo7KFahZr+3JkErs2VvpdxuqVNiiOItwf4Op552McF1iT/r/AEAQNPhEzQAvzhSbNPaHZ6tNft1CdewvhalJIQoyOSZ1beEB2ncoBiNSLMoJNigkgqHvt15/FacwE/Zss9zcym9W8uZ7fdKjPE0+DtcZJOLdf4AAKCJkPgDaHalFQ59+X2Z3G6pS1LIScuvDQaDurcP04UDY2UwSAfybdqXV9PM0aK121qX+PfrGuHnSI4XFxUkk1Gy1bq1P5/XNgAAaBok/gCaVbXNqS++K1Gt063EmGCNSIv+yc798ZZg9a9L2r7dYVW1zdkcoSIA1Nhd2p1TJallJv5Go0GJ0Z5Z/61H9boAAABoTCT+AJrVuh/KVWVzyRJuUsY5MTKdZsO+fl0jFBsZJLvDrW92lMvtpiwaP+2HQ1Vyujw3j9rFtKz1/V6JdXF5lyQAAAA0NhJ/AM2muLxWB/I93ctH9o9WSPDpvwWZjAaN6GeR0SAdKrRpx8HqpgoTAeToMv+fqizxl3Z16/y37KvkhhYAAGgSJP4Amo13L/WuSaGKjTrz2dfYyGCl1+3D/uX3pSoooxM6Ts2X+HdpeWX+XgnRwTIapCJrrfJKeE0DAIDGR+IPoFkUlNl1uMgug0FK797wJCytc7jiLZ6S/8Wf5jVihAg0Tpdb2w94Ev+0ruF+jubkgkwGyv0BAECTIvEH0Cw2ZXsSmu7tQ2UJD2rweYxGgwb3ipIkfbaxRMXltY0SHwLP/rwaVdlcCgsxqltSmL/DOaWU+BBJP1YoAAAANCYSfwBN7kixXXkldhkNUv+uZ7+XemJ0sJJjg+VwurV0dWEjRIhA5E2i+3YOl8nUMtf3e3WI/3GdPwAAQGMj8QfQpNxutzbt8azt75kSpsgw01mf02AwaFBPz6z/0jVFqrGzvR+O9+P6/rO/2dTU2tfN+B8qsKm0gioWAADQuEj8ATSpw0V2FZbVymSU+jfiPurdO4QqOc6s8mqnPllf0mjnRWBwu92+2fN+jfi6ayqhZqO6JoVKotwfAAA0PhJ/AE1q815PEtO7Y7jCQs5+tt/LaDDoipGJkqR3VhXI6WIbNPwov7RWRVbPDafUTi17fb+X9waF998MAABAYyHxB9BkCso8yZfRIKU1wXZqE86NVVSYSUeK7fp6a1mjnx+t17b9nuS5R4cwhZob74ZTU/JWxDDjDwAAGhuJP4Ams60ugemYGKJQc+O/3YSaTZo8PF6S9N8vC+R2M+sPjx/X97f8Mn+vft08se7JrVZlDX0rAABA4yHxB9AkbLUu7TxUJUnq2aHpSq2njEhQkMmgnYeqtHU/M6Xw8L4WWsP6fq/EaLOSYs1yuaUdB3gtAwCAxkPiD6BJfLWlTLZatyJCjUqOMzfZdWKjgjV+cKwk6d1VbO0Hqbzaof15NZKaZolJU/KV+++v8nMkAAAgkJD4A2gS/1tXJEnq0T5MBkPT7qF+6fkJkqRvdlhlrXQ06bXQ8m3fXyW3W0qJNys2Ktjf4ZyRtLrEfxvr/AEAQCMi8QfQ6HIKbfp+jydx6d6EZf5e3ZLD1L19qBxOt77cXNrk10PL5m3sl9aKyvy9vD0JdhyslMNJzwoAANA4SPwBNLqP1xVLkrokhSgitHk6qo8d5Cn3/3xjSbNcDy2Xb31/Kyvzl6ROiSGKCjPJVutW9uFqf4cDAAACBIk/gEblcLr1yQZP4t+c66svHBAro0HafqBKhwttzXZdtCx2h0s/HPSsj29Njf28jEaDr1KBbf1wpiprnNqUXaHvsiu0/UCl9uRWK6fQJluty9+hAQD8LMjfAQAILN/utKqk3KGYyCB1Sw5VWWXzbEsWZwnWwJ6R2rCrQp9/V6Lrxyc3y3XRsmTnVMvucMsSYVJKQoi/w2mQfl0itHa7VVv3V+qKUYn+DgetgNvtVnZujdb/UH7CJSIhwQZNGhbvh8gAAC0FM/4AGtVH33pm+8cPjpXJ2LRN/Y41blCcJE+5v9vN+ui26Ogy/6ZuKtlU+h0148/rGD+lqsapLzaVau12qxxOtxIswerdMUxdkkKUHGdWeIhRtlq3lnxVqGXfFPk7XACAnzDjD6DRlJTXat1OqyTp4iFx+n5PRbNe//x+FoWajcottmvHgSr1bYVrvHF2vOXxrbHM36tnSpiCgwwqq3Qop9Cujomts3IBTS+n0Kavtpap1uGW0SgN7B6p1M7hMh5108vhdGv1tjIdyLdp3ruHtDe3WndMTlGQqXXeGAMANAwz/gAazVdbyuRyS707hqljYmizXz/UbNIF/aIlSZ/R5K/Ncbvdvo7+rbGxn5c5yKjUjuGSpK37m/fmGVqP8iqHVm3xJP3xlmBNHBqvvl0i6iX9khRkMmhk/2iNSLPIYJCWrinSrFf3yO5g3T8AtCUk/gAazcotpZKkUekxfovB293/y+9LVcsH2zblUIFN1iqnzEEG9WiGbSSbUj8a/OEUnC63Vm0pk8PpVruYYF10bqyiI05exGkwGDSkd5QevaGrwkKM2pRdoTc/y2vGiAEA/kbiD6BRFJfXavNeT5Liz8R/QI9IxVuCVF7t1Lc7y/0WB5qfd31/aqdwBQe17l9v3h0xtpH44wS+212h4nKHQoINuqBftIyn2U9leN9o3T+tsyQpMytfO+t2wAAABL7W/ckIQIvx9ZYyud2epCsp1uy3OExGg8YM8Mz6f/4d5f5tSSCs7/fq2yVcBoOUU2RXSXmtv8NBC3KowKYddQn78LRohYeazuj7L+gXrTEDYuRyS8++fUB2tvoDgDaBxB9Ao/hyc6kkaVR6tH8DkTSurtx/7XarKmuaZztB+J8v8W/F6/u9osKC1CXJ0yfD27cAqKpxas32MklSn07h6tjALStnTElRbFSQDubb9ManRxozRABAC0XiD+CsFZfXaktd0jWyf4x/g5HUrX2YOiWGyOF069sdVn+Hg2ZQbK1VbrFdBoMCZjcH7w0M1vlD8jSv/HqbVbZat+KigjSwZ2SDz2WJCNK9UztKkv67soCbSwDQBpD4AzhrX7WQMv+jnV/X3f+rrWV+jgTNwbu+v1tyqCLOsPS5pfI1+CMpg6TDRXblldhlMkoj+0fLdJrr+k9meN9ojR8cK7dbmpN5QDV2Sv4BIJCR+AM4ayvryvxH+7Gp37Eu6O9J/L/dWc4H2jbAO2OZFiCz/dKPif/uw9WqsbNkpS1zu93atMeztWPvjuGKCj95B/8zccfkFMVbgpRTZNeSrwoa5ZwAgJaJxB/AWSm2HlXm3wLW93v17BCmdjHBstW6tGEX3f0DXSCt7/dqF2NWYnSwXC75mrmhbTpYYFNJuUNBJkOj3tyKDDPp5ks6SJLeXVWgahs3mAAgUJH4Azgrq+rK/Pt0Cle7mJZR5i959q2+wFvuv4Vy/0BWbXMqO7daUmB09D+ar9yfdf5tlsvt1vd1s/19OoUr1Ny4H90yzolRh3izrFVOfbi2qFHPDQBoOUj8AZyVlVtKJUmjz4nxaxwnckFdo8G1O8pU66DcP1DtOFgll0tqFxOsxBZ086kx0OAP+/NqVFbplDnIoL6dwxv9/CaTQddcmCTJ0+iPpVEAEJhI/AE0WLG11peQjOzfcsr8vfp2DldsVJAqa1zalF3h73DQRLbtC7z1/V79unme044DVXI63X6OBs3N5XJr8x7P67tvlwiZg5vmY9uFA2OVHGtWaYVDy79h1h8AAhGJP4AG+3rbj2X+LXGm1Wg0aEQa3f0DnbfrfaCV+UtSl3ahigg1qtru0t4j1f4OB81sz5EalVc7FRJsUGrHsCa7TpDJoJ9f2E6SlPllvmy1zPoDQKAh8QfQYKu3eZJp79Z5LZG3EmH1NqucLmZMA43T6db2A57Gd4HU2M/LaPyxmRvl/m2L0+XW5r2eSqV+XSMUHNS0H9nGDYpVu5hglZQ79L9vi5v0WgCA5kfiD6BBKmuc+r6uBNU7q94SpXeLVGSYSWWVDhKnAOTZ6s6lyFCTuiSF+jucJuFr8Lef129bciCvRlU1LoWZjeqV0vhr+48VHGTU1WM8s/7/ycqXnb4oABBQSPwBNMi3O61yON3qlBiijokh/g7npIJMBo1Is0iSvqbcP+B4b+akdY2Q0WjwczRN4+gGf243VSttxc5DnkqW3p3CFWRqntf2hHPjFG8JVpG1Vp+uL2mWawIAmgeJP4AGWbPNKkkaXpdUt2TepQhfbS2Ti3L/gLJln6cUOr1b4JX5e/Xu6En8issdOlJi93c4aAaFZbUqsjpkNEg9OzTd2v5jmYOMmjY6UZK05OsCbjQBQAAh8QdwxmodLn2705P4t+Qyf6/BPaMUZjaqsKxWu3JokBYoXC63b8a/fwA29vMyBxvVu66xG8tV2oYf6mb7uySFKtTcvB/Vxp8bp1CzUQfzbdq8l9cbAAQKEn8AZ+z7PZWqsrkUGxWk1I5Nv/b0bJmDjRqSGiXpx4aEaP0OFthkrXIqJNions2wBtqfaPDXdtTYXdqfVyPJU+3R3CJCTRo7MFaS9OGawma/PgCgaZD4Azhja7Z7kufhfS2tZl21tzKBxD9weDue9+3cfGug/cXX4I/EP+DtPlwtl1uKtwQpITrYLzFMGh4vybM8qtha65cYAACNi8QfwBlxu91a7V3f37fll/l7nZdqkckoHci3KafQ5u9w0AjaQpm/V1pnz3M8WGBTaYXDz9Ggqbhcbu3yNvXzYzVV9/ZhSusSLqdL+t86tvYDgEBA4g/gjOzKqVaRtVahZqMG9oj0dzinLTLMpHO6e+Jl1r/1c7vdvvXH/bu1ntdhQ1kigtS5nWf3jO0HmPUPVHtya1Rlcykk2KAu7fy7PeWkYQmSpGXfFMnppMkfALR2JP5tUHN16aUbcGBaU5c0D+kdJXNw63oL8VYokPi3fnkldhVZaxVkMii1U2Cv7/ei3D/wfV+3fKVnSrhMfl6+MjI9WpYIkwrLavVNXTNXAEDrFeTvAND8DAaDVm0plbWy6cpFLRFBGtk/psnOD//xlvm3hm7+xxqRZtGCD3K0/UCVSitqFRPpn/WzOHve2f5eKWHN3vXcX/p1idDyb4pJ/APUviPVyim0y2DwvK79zRxk1MVD4pSZVaClawpb5Xs+AOBHJP5tlLXSoeJy1onizOQW27Qvr0ZGo3ReXZf81iQxxqyeHcK0+3C11m636uLz4v0dEhrIt76/W+Cv7/fyzvjvPlytGrurzdzwaCuWf+NZS98xIUQRoSY/R+MxcWi83v6yQBt2VehwoU0dEkL8HRIAoIH41ADgtK2pm+1P7xapqPDWed/Q191/O6WrrdmWupLo/l0Df32/V1KsWfGWIDmcbt8+7wgMdodLX3xXIknq0cH/s/1eyXEhOreX5ybvh98U+TkaAMDZIPEHcNq+rlsbP6Kvxc+RNNyINE/sG3eVq8bu9HM0aIji8lrlFHlKor3727cFBoNB/eqe79b9lPsHkm92WFVe7VREqFHt483+DqeeycM9Tf4+XV8su8Pl52gAAA1F4g/gtJRVOrStrrx6eCte69k1OVTJsWbZHW6t31Xh73DQAN4y/27JoYoMaxkl0c0lra7c31vxgMDwyXrPbH9qp3AZDf5t6nesIalRircEyVrl1Lc7qJQCgNaKxB/Aaflmh1Uut9S9faiSYlvWjNSZMBgMGl436796K939W6Mt3m382lCZv5d3S8qt+6pUy+xrQCgur9W6HzwJdd/OLW+HCpPRoHGD4iRJH9fdoAAAtD4k/gBOi3cLvEDo7Ox9Dt/ssLI/dSu0ZV/d+v421NjPq0u7UEVHBMlW69JO1vkHhM83lsjlkvp0CldcVMvcaWTCubGSpHU/WFVcXuvnaAAADUHiD+An1dhd2rCrXFJgJP79ukQoKsyk8mona6VbmYpqp/YeqZH0Y5f7tsRoNOic7p7n/X02r93Wzu1265P1nm7+E4bE+Tmak+uYGKq+ncPlcnluVAAAWh8SfwA/6bvd5bLVutUuJljd24f6O5yzZjIZNKyuQaG3kgGtw/d7KuR2Sx0TQ1rs7GhTG9DDU+6/aU+5nyPB2frhULUO5NtkDjIo45wYf4dzSuPP9dyY+GR9sdxuKqUAoLUh8Qfwk7xb3w3vGy1DC2s81VDeBoWrt1n5ENuKfJftSXYH9mh76/u9BnT3bK+2bX+VbLWs82/NvLP95/eLVkRoy25UmXFOjEKCDTqQb9MPh6r9HQ4A4Az5PfHfv3+/Hn30UV122WVKS0vT5MmTTzguKytLl19+udLT0zVhwgQtXrz4hOMWLVqksWPHKj09XVdeeaXWrl173JiKigo9+uijGjZsmAYNGqQ777xTOTk5jfq8gEDhdLm1ti7xH9Gv9W7jd6xze0XKHGRQXold++pKx9HyfZftWd/flhP/lASz4i1Bcjjd2n6Acv/Wyl7rUtamUknSRS24zN8rItSk8/t5bph6b1gAAFoPvyf+u3btUlZWlrp06aIePXqccMzGjRt11113KS0tTS+//LKmTp2qJ554QpmZmfXGLVq0SHPnztV1112nhQsXqkuXLrrtttu0c+fOeuPuv/9+ff7553rkkUc0d+5c5efn66abblJNDR/+gWNtP1CpskqHIkNNAdVFPdRs0qBenpnTryn3bxWKrLU6mG+TwfBjd/u2yGAw+Gb9N2WzrV9r9fW2MlXUOJUYHawBreT1PKGu3D9rU6nsVJsAQKvi98R/7NixysrK0t///nf169fvhGPmz5+vtLQ0PfXUUxo+fLjuuusuXXXVVXruuefkcnl+8djtdi1YsEDTp0/XLbfcohEjRugvf/mLOnbsqBdffNF3rk2bNmnFihV68sknNXnyZI0ZM0bPP/+8cnJy9O677zbLcwZakzXbPLP9Q/tYFGQKjDJ/rxF12/p5nyNaNm+S27NDmKLCg/wcjX+d08PT4I/Ev/X6tG5rvPGDY2U0to731gHdI5UYHayKGqdWb+eGKQC0Jn5P/I3GU4dgt9u1Zs0aTZo0qd7xKVOmqKCgQNu2bZMkbdiwQeXl5fWWCphMJk2cOFFZWVm+NbxZWVmyWCwaPXq0b1yHDh00ePBgZWVlNdbTAgKC2+32Nb8bnhY4Zf5ew/pYZDBIuw9XK7/U7u9w8BO86/sHtOEyf6+BPTwz/j8cqlKVzennaHCmCsrs2rDb83r2Ns1rDYxGg8YP9mzt98k6uvsDQGvi98T/pxw4cEC1tbXq3r17veM9e/aUJGVnZ9f7+9hxPXr0UGVlpfLy8nzjunXrdlyDsp49e/rOAcDjQL5Nh4vsCjIZdG7vKH+H0+hiIoOV1sUzc8qsf8vmdrv13W7v+v7Aey2eqaRYs5JjzXK6pK37WOff2ny+sURut9S/a4Q6xIf4O5wz4r1RsXF3uQrLav0cDQDgdLX4xL+szDPbaLHUn230fu193Gq1ymw2KzS0/lZj0dGeRjSlpaW+cVFRx39otFgsvnMB8FhTV8o5qGekwkNadsfphhrOtn6twuEiuwrKahVkMqhf1wh/h9MinFNX+fD9Hsr9WxO3261P1nma401oRbP9Xh3iQ9S/W4RcbumzjTT5A4DWosUn/l4n20Ls6OMnGuMt8f+pcac6DrRVq7fWbeNXt/VdIBpR99w2761QebXDz9HgZLxl/n07hyvU3Gp+dTUpb0M41vm3LtsPVCmnyK5Qs1Gj0lvne+uEwZ4bFp+sK2Y7VABoJVr8pyfvjP2xs/FWqych8c78WywW2Ww22Wy2E47znsdisfiOHTvu2KoCoC0rKLVr56EqGQw/zooHopSEEHVuFyKnS/p2R7m/w8FJUOZ/PG+vg92Hq7lp1Yp4t8Ib2T9aYa20kmpUerRCzUblFNm1/UCVv8MBAJyGFp/4d+7cWcHBwdqzZ0+947t375Yk3xaA3r+PXaefnZ2tiIgIJSUl+cbt3bv3uDvUu3fvPul2gkBb9NVWz822fl0iFBcV7OdompZ31n8NXapbJJfL7StnH9iTxn5e8ZZgdUwMkdstbdnLOv/WoMbuVNb3pZJaZ5m/V1iIyVet4L2RAXg1VxUI1SbAmWnx+yGZzWYNHz5cy5cv14033ug7vnTpUiUmJiotLU2SNHjwYEVFRWnZsmW+Y06nU8uXL1dGRoavjD8jI0Pz58/XypUrfZ39c3NztWHDBs2aNat5nxzQgn21xZMEX9C/dZainokRadH694p8rdtZLrvDJXNQi78n2qbsOVIta5VTYWajencM93c4LcqA7pE6VGDTpuwK3w0stFxfb7Wq2uZScqxZ/Vt5r4rxg+P0yfoSZX1fqjsmp7AEBz4Gg0GrtpTKWtl0lUiWiCCN7B/TZOcHApHfE//q6mrfNno5OTmqqKjQRx99JEkaOnSo4uLiNHPmTF1//fWaNWuWpkyZog0bNigzM1OzZ8/2bQdoNps1Y8YMzZ07V3FxcUpLS1NmZqYOHjyoOXPm+K43YMAAjRkzRg8//LAefPBBRUZG6rnnnlNKSoqmTp3a/D8AoAUqLq/V1v2eGcTz+wV+MtErJUzxliAVWR3alF2h81IDd2lDa+Qt80/vFqEgE71YjjagR6Q+XFuk71jn3yp8XDc7Pv7cWBmNrfu13L9rhJLjzDpSbNfXW8s0dlCsv0NCC2KtdKi4nCVIQEvi98S/qKhIv/rVr+od8379+uuva9iwYRo0aJBeeOEFzZkzR0uWLFFycrJmzZqladOm1fu+m2++WW63W2+88YYKCwvVu3dvLVy4UKmpqfXGPfvss3rmmWf02GOPqba2VsOGDdO8efOO2xEAaKtWbyuT2y317himdjFmf4fT5IxGg4b1jdaytUVava2MxL+F8TavG9iT9f3HOqd7pAwGaX9ejQrLapUQHdjLclqzvBK777U8fnDrLfP3MhoNGj84Vv/8NE8fry8m8QeAFs7viX/Hjh21c+fOnxyXkZGhjIyMU44xGAy69dZbdeutt55yXGRkpB5//HE9/vjjZxQr0Fb8WOYf499AmtH5ad7E36qZl7plYma5Rah1uLS5bv36wB6s7z9WdESQUjuGa8fBKq37wapLzov3d0g4iU83eGb7B/SIVFJsYNxQHT84Tos/y9Om7ArlldgD5nkBQCBiQRaAesqrHNpU10htZBso8/ca0CNSUWEmlVY4tHkfZdMtxc6DVbLVuhQdEaQuSVRlnYi3QuXbnexK0VK5XG59ur5EknRRK27qd6ykWLNvW0nvjQ0AQMtE4g+gnjXbrXK5pG7JoeqQEOLvcJpNkMng62ewcjPd/VuKdT94ktmBPSJb/ZropnJeH88SiI27ylXrcPk5GpzIln2VOlJiV1iIMeD6pnh3J/h0fYlcLrqsA0BLReIPoJ5Vbaib/7FGpcdI8ix1cDr5ANsSrN1hlSQN7UPfhZPp0T5MsZFBqra7fE050bJ4t7zLOCcm4Lrfn98vWmEhRh0psWvLPl5/ANBSBdZvHwBnpbLGqQ27PDOsbXGbnAE9ImUJN6ms0qHv91Lu7295JXbtO1Ijo0Ea0pvGfidjNBo0JNXz86Hcv+Wptjl9N1QnBFCZv1eo2aiMc2Ik/XiDAwDQ8pD4A/D5dodVDqdbHRND1Lld2ynz9zq63H8V5f5+923dbH/fLhGyRPi9F22L9uM6f6ufI8GxVm4uU43dpZSEEPXtHO7vcJqE94bGqi1lqrY5/RwNAOBESPwB+KzaWlfm3y9aBkPbXE/tLfdftbWUcn8/85b5D6PM/ycN6hklo1E6mG/TkWKbv8PBUT6pa3o34dzYgH1f7ds5XCkJIaqxu+iRAgAtFIk/AElSjd2pdXVlwm1xfb/XgO6ecn9rpZNyfz+qtjn1Xd2e56zv/2mRYSb16xIhSb5/x/C/w0U2bdlbKaNBGjco8Mr8vQwGgyacGyvpxxsdAICWhcQfgCRp9TarbLUuJceZ1bNDmL/D8RtTve7+pf4Npg37LrtCDqdbybHmNrnspCG85f7fUO7fYnxat+Z9UM8oJUQH+zmapjVuUJyMBmnL3kodLqLqBABaGhJ/AJKkL77z7DF94cDALUc9XaPrGlV9tZXu/v6ydntdmX9fS5t/PZ6u8+oa/G3KrpCtlm39/M3lcuvTDZ731QlDYv0cTdNLiA7W4F6e1+CnNPkDgBaHxB+ASiscWl/XzX/swBj/BtMCnNMtUpYIyv39xeVy+2atKfM/fV2SQpUYHSy7w63v9/C69bdNeypUUFaryFCTRvRtG8unxteV+3+6oUQuFzdNAaAlIfEHoJWbS+VySb1SwtQxMdTf4fidyWTQBXXl/l9+X+rfYNqg3YerVVLuUJjZqP7dIvwdTqthMBjo7t+CeLe2yxgQI3Nw2/i4NaJvtCJDTSooq9Umbj4BQIvSNn4TATilo8v84eHt7v/11jLVOiibbk7f1HXzH9w7SuYgfk2dCW+5/7c7y+V2M+PqL5U1Tn21xdPd3rvVXVtgDjYqY0CMpB9vfAAAWgY+UQFtXG6xTdsPVMlokDLq1rbDU+4fGxUka5VT39IlvVn51vdT5n/GBvSIVJDJoCPFdh3Ip8Gav3y2oUR2h1tdkkLVu2PbapbqvdHx1ZYyVdY4/RwNAMCLxB9o41Z8VyrJkzDEWQK76/SZMJkMGjfIu16VmavmUlhWq92Hq2Uw/Dh7jdMXFmLS4J6RkqRV7ErhF263Wx+uLZQkTRwa3+aaU/buGKYuSaGyO9zKYqkUALQYJP5AG+Z2uynzP4Xxgz0zV9/ssKq0wuHnaNoG79r01I7hionkRlRDeHelyPq+lHJ/P9iyr1IH8m0KCTZq3OC2975qMBg0oa7J3/K1RbwGAaCFIPEH2rDdh6t1sMAmc9CPe9fjR12SQtUrJUxOl7RiU4m/w2kTvt7qWRc9tC9l/g01PC1awUEGHSywad+RGn+H0+Z8uKZIknThwBhFhJr8HI1/jB8cp+Agg3YfrtaOg1X+DgcAIBJ/oE37YqMnmR3e19JmP6D+FO96VRpVNb3Silpt2O3ppzC6rrkizlxEqElDenuWSVBq3bxKymv1Vd3Nq0nD4/0cjf9ERwRpTF2Tv6Wri/wbDABAEok/0GY5XT+uv6TM/+QyzolRkMmgPbk12pNb7e9wAtqX35fJ5fKsEU5JCPF3OK2at9z/S8r9m9XH64vlcLqV2ilcPTuE+zscv5o8PEGS9OXmUpVW1Po5GgAAiT/QRn23u0LF5Q5FhZl0bm+aqJ2MJSJIw+vKzj9l1r9J0W+i8QzrY1FIsEG5xXbtPswNq+bgdLm1bK1ndnvSsLY72+/Vu2O4UjuGy+F066Nvee8EAH8j8QfaqOXfeD6gjhkQo2D2Sj8lb7n/59+VyuFk9rQp5BbbtOOgZ1vJ0WwredbCQky+7RC/pNy/Waz/oVz5pbWKDDPxGq4zeYTnBsiytUVy8t4JAH7Fp32gDSosq9Xq7d51qAl+jqblO7dXlGIjg1RW6dC6uq7zaFz1tpWMopt/Y6Dcv3l9uMazhd9F58YpJJiPV5KnV4clwqSCslqt3cF7JwD4E7+ZgDbof+uK5HJJ/btGqEtSqL/DafFMJoPGDvKUn3+yge7+jY1tJZvGkFSLwsxG5ZfWascBOqs3pbwSu779wdOYciJl/j7mYKMuGeL5eSytuzECAPAPEn+gjXE63Vr+jWe9JR9QT9/4uv24124vU2mFw8/RBJbsXM+2ksFsK9moQoKNGp7mKfenu3/T+mB1odxuaVDPSBpTHmPisHgZDdLG3RU6mM/2kgDgLyT+QBuzdodVRdZaRUcE6YL+JFmnq2tymHqlhMnp8lRMoPF4y/yH9WFbycbmLfdftaVULhfl/k2hotqpZXU9Uy6/INHP0bQ8SbFmDa3rN7F0De+dAOAvJP5AG+PtOn3RkFiZaep3Ri4739MP4YPVRTT5ayROl1srNpVKosy/KQzuFaWIUKOKrA5t2Vfp73AC0rK1haq2udQ1KVTnpbJDyol4t/b7ZH2xyquomAIAf+BTP9CGHC6yaf2uchkM0s+GUuZ/pkadE6PYqCAVWWu1akupv8MJCFv3VarIWquIUKOGkDQ1OnOQURf0j5EkfbyOLdUam73WpSVfedauXzU6UQaDwc8RtUyDe0WqW3Koqu0uvb+atf4A4A8k/m3Mhl3l+veKPO08WKX8Ersqa5yUf7Yh3i38zu0VpfZxrEM9U+Ygo29/bu+HfZwdb1O/kf1jqEBpIhPrbvJlfV9Kf4pG9tnGEpVUOJQYHayMAVSsnIzBYNDPL2wnSXrvq0JV25x+jggA2p4gfweA5uN2u/XMv/fLWln/F67JKHVMDFXXpFC1jzfLZGTGIhDZHS59vJ6mfmdr0rB4/euLfO08WKXtByrVt3OEv0NqtSprnL6mc5T5N53UTuHqlRKmXTnV+nh9sa7OaOfvkAKC0+XWf7/MlyRNHZmoIBO/O09lZP8YdYg/osNFdi3/plhXjKIfAgA0J6ZX2hCDwaBfTe2k8YNjlZJgVmSoSQaD5HRJ+/NqlPV9qd5ZWaC1260qq2RWKNCs2lwma6VTCdHBGppq8Xc4rVZMZLAuHBgjiVn/s/Xp+mJV21zqlBii9G7cQGlK3jXWH64plJMqr0axZluZcorsigwz6ZLz4vwdTotnMhp8N53+uzJfdofLzxEBQNtC4t/GnN8vWvdP66wrRibqsgsSdM2F7XTxkDildgpXqNkou8Ot3Yer9eHaIn2zw0o5XoBwudx6u25mauLQeJmYmTor3s7dq7aUqqDU7udoWieXy633vvbcOLn0/AQZqTRqUhkDYhQVZlJ+aa3W7Sz3dzitntvtVmZWgSRpyvB4hYWwG8XpGDsoVgnRwSoud+jTDSX+DgcA2hQS/zbOaDAoITpYQ3pHaerIBI0bFKuOCSFyu6VdOdV6f3WRvt9TQQfzVm7tDqv2HqlRWIhRk4dT5n+2urcP0zndI+RySR+sYda/Ib7ZaVVusV2RoSaNH0yZf1MLCTbqoiGeWemlvGbP2ua9ldp5qErmIIMurdvtAz8tOMioK+tK/DOz8uXkswUANBsSf/gYDQYlx5mVMSBG4wfHKt4SJIfTrc17K/Xh2iJmNlspt9uttz7PkyRdOiJBUeG09mgM3ln/5d8Uq8ZOZcyZeq9umcQlQ+MUama2tDlMHBYvg0Fa90O5Dhfa/B1Oq3X0e+qEc+MUExns54hal0vOi5MlwqQjxXZfjw8AQNMj8ccJJcWadfGQOI3sH63wUKMqqp36ZH2Jvt9TwS4Arcy6H8q1K6daIcFGX7KKsze0j0XJcWbfvw2cvr1HqvVddoWMRmnKCGZLm0uH+BCd28uzZeKHdTt84Mxt2FWu77IrFGQyaBqNEs9YqNnk+130n6x8PlMAQDMh8cdJGQwGdUkK1aRh8eqaHCq3POWNH68vUXkVzf9ag6NnpiYNj1dMJLP9jcVkNOiKkZ4Pr299kacaO42qTtf7dWv7z0+LVrsYs5+jaVu8Tf4+XlfMa7YBnC63Fi3PleTpTZEUy+u3IaYMT1B4iFH782p8W3oCAJoWiT9+kjnIqAv6ReuCftEyBxlUZK3Vsm+Kdaigxt+h4Sd8l12h7Qc861CvZOukRnfJeXFKijWrpNyh978u8Hc4rUJZpUOfb/R80KcCpfkNSY1SUqynUiXrexKuM/XFdyXae6RGkaEmXTOG2f6Gigwz6ed1P79X/3eE5VJtgNvtVo3dpSJrrfbn1Wj7gUr9cKhKe49U61ChTXkldm5GAk2M6T+ctq7JoUqMCdZXW8tUUFqrrO/LdE53h/p3jZDBQEfulujNutn+S86LV1wU61AbW3CQUdMnJOsv/zmgzKwC/WxYvKLCeFs9leXfFMnucKtXSpjSuoT7O5w2x2Q0aNKweP3fR7l6+8sCjR8Uxy4fp8le69LrHx+RJF09ph39Us7S5Rckatk3xcorseu/Kwt03bhkf4eERlZZ41ROoU2HCmwqKKs9rUbRUeEmtYsJVmK0WclxZkWE0gMGaCzM+OOMRISaNH5QrHp3DJMkfb+nUis3l6mW/XhbnM17K7Rlb6WCTAZdlcHMalPJGBCjrkmhqqhxKjMr39/htGi1DpeWrvGsLb/8gkRuGPrJxGHxigoz6VCBTZ9uLPZ3OK3G+6sLVVBWq4ToYDr5NwJzsFE3X9JekpSZVaDCslo/R4TGYK106N8r8vTWF/la8lWhvt1Zrtxiuy/pDzMblRAdrC7tQtQpMUTJsWbFW4IUGeZJ8MurnMo+XKM1261a8lWhPv+uRAfya+gFATQCblfjjBmNBp2XalFsVLC+3WHVwQKbrOtKNGZAjO+NG/7ldrv1z089M1MXnRunxGjWoTYVk9GgX16crMde36f3virUZecnKt5CdcWJLF1TpCJrreKigjQqPdrf4bRZEaEm/fzCdnplWa7++WmeLhwQK3Mw8wCnUl7l0L+/8NzYmz4hWSH8vBrFqPRovfd1uLbtr9I/Ps7V/dM6+zskNFBusU3vrirQx+tKZKv1TAYZJCVEByslMUQd4syKCg9S0CkqjGy1LhWU1aqg1K78kloVWmuVW2RXbpFdoWajenQIU59O4Qo18+8PaAj+5aDBenYI0/hzYxVqNqqs0qH/fVvMHfsWIuv7Un2/p1LmIIOuZh1qkxvWx6K0LuGyO9y+5RWor7zK4fvZ3DAhWcFB/Prxp8nDExRvCVZhWa0+XEuH/5/yrxX5qqhxqmtyqMYOivV3OAHDYDDotokdJEmfbijRrpwqP0eEM5VTaNPTb+7TrX/doQ9WF8lW61L39qEaNyhGV4xK1EVD4tSvS4Rio4JPmfRLUkiwUR0TQjSoZ5QuPi9Ol46IV1oXT6JfY3dp675Kvfd1ob7fUyF7LZWmwJnikxfOSmK0WT87L06xkUGqqXXp0w3FOpBH0z9/qqxx6uUPD0vyrEOl63TTMxgMuuliT8nqR98WKYc90o/zry/yVVHtVNekUE04N87f4bR5IcFGXTcuSZL0rxV5qrLRXO1k9uRW672vPM07b76kvUxGlqg0pj6dIzRmQIwkaeGHh+V2U9LdGpRXO/TS0hzdMXeHvtxcJpdbGtI7Sk/d0l3P39NbaV0iznpmPio8SIN6RmnqBQkalR6tuKggOZxubd5bqX98fERvf5nPDQDgDJD446yFh5o04dxYpSSY5XRJK7eUad0P5fzy9pPFnx5RcblD7ePMmjaa2f7m0r9bpM5LjZLLJf3fR7n+DqdFOVxk0/urPVv43TqRxKmluOjcOKUkhMha6dS7K9mV4kQcTreezTwgp0s6v1+0hvSO8ndIAemmS9rLHGTQlr2VWrGp1N/h4BScTrfe/7pQt/xlh5Z8VSinSzovNUov3Ntbj9/UXYN6RjV6/xaj0aDO7UJ1yXlxGpUeLUu4STW1nq01Zzy3U+t/KG/U6wGBisQfjSI4yKjR58Qota7p3+ptVv3tnUM0/Wtme3Or9V5dgnXXpSms221mN13SXiaj9PXWMn35fam/w2kxXvtfrhxOt87tFaVze1v8HQ7qmEwGTZ/g6aT+35UFKq1w+DmiluffK/K0J7dGUWEm3X1ZCg0pm0i7GLN+PsZTgfLCezkqKLP7OSKcyJ7cav36hV1a8EGOyqud6pIUqidu6q7ZN3ZXt/ZhTX59g8FzA2DSsHiNHxSjeEuQDhfZNevVPXr6zX0qsrLcFDgVsgI0GqPBoCGpFg3pHSWDpI/XFeuR1/aqvJoPk83B5XLr+fcOyeWSLugfrSGpJFjNrVtymO/D6/z3D6m0gg8h2/Z7dv4wGqRbJrb3dzg4xsj+0erZIUzVdpf+s4L+FEfbk1utt+r6Utx1aYpi2RK1SV09pp1SO4arosapOZkH6eLegtgdLr3+yRHd+/wP2n24WpFhJt19eYrm39Nb5/qhCsZoNKhvlwi9dF8fXXZ+gowG6cvNZbptzg69/3Uhrx3gJEj80ehSO4Vr0vB4hZmN2pRdofsX7FZuMWuem9pnG0u0bX+VQs1G3TGpg7/DabOuubCdurcPlbXSqeffy2nTS17cbrev38RFQ+LULbnpZ4RwZoxGg2682DPr//7qQpqr1Tm6xH9EmkUZdWvQ0XSCTAb99urOCgk26LvsCt/yIPjXjgOVumfeD3rr8zw5XdIF/aL10n2pmjQsQaafaNbX1CJCTbpzSoqeu7uXUjuGq9rm0oIPcvTAy9k6VMDnTuBYJP5oEt2SQ/XXO3sqITpYBwts+vULu7R1X6W/wwpYRdZavbLck2BdNy5JiTE09POX4CCjfnNVZ5mM0ldbyvTl5lJ/h+Q3H68v1o6DnptRN4xP9nc4OInBvaI0sn+0nC7pL/8+4NuKqy2rV+J/eUdK/JtJx8QQ3VrX5f//PsrVfpoF+02N3aWXlx3W/S/u1oF8m2Iig/SHX3TRrOu7Kq6FVb/07BCuZ2f01F2XpijMbNTWfZW66+87lZmVL6ez7d58B45F4o8m0719mP52Vy/17BAma6VTD76SrY++ZduoxlbrcOmpN/fJWulU9/ahuvyCRH+H1Ob16BBWb71qSXnbK/k/kF+jBe97bkb9YmyS4iwt64MifmQwGHTP5R0VFxWkgwU2vdrGm1Nu2Vehf32RL0macWlKi0tyAt2kYfEa0jtKtQ63/vKfA/QK8oPv91Ro5t936p2VBXK5pbEDY/XSr1M1Kj3G36GdlMlo0JQRCVrw61QN7hWpWodb//dRru5bsEt7c6v9HR7QIpD4o0nFW4L1lzt66IL+0XI43XrunUN6fglN/xrTouW52ra/ShGhRj38i64/uU8umoev5L/KqXlLDrWpkn9brUtPv7lftlqXBvWM1JWjuBnV0lkigvSbqzpJkt77ulAbdrXNLtmHi2x6/I19cjjdGp0e7dtmDs3HYDDovis7KSrMpOzD1XplWdu+EdWcqmxOPb/kkH7/crYOF9kVbwnWY7/spt/9vLMsEUH+Du+0JMWa9cRN3fWbqzopMtSkXTnVuuf5H/TGJ0f47Ik2j8QfTS7UbNLDv+ii6Rcly2CQPlxbpD8s2tMmZ0Eb2xfflei9rz3rIH97dWd1SAjxc0TwOrrkf/U2q17/5Ii/Q2o2C5ce1r68GsVEBum3V3eWke37WoVze1s0ZXi8JGnO2wdUXtW2GrNWVDv1//6xV9Yqp3qlhOm+qzpT4u8ncZZg/fpKz42o91cX6h22m2xy63Zadefcnfpwracy82dD4/TSfaka2qf1NQo2GAyacK4n/vP7eZYxvfl5nu55fpd2HqSPCdouEn80C4PBoGsvTNKjN3RVeIhRW/ZV6p7nd+n7PRX+Dq3V2nukWs+9c0iSZ3Z5eN9oP0eEY/XoEKZ7pnaUJP3ri/w2sdRl5eZSLfumSAaD9LurO1Mm3crc/LMOSkkIUZHV0aaaUzqcbj315j4dLLApITpYf5zeTaFmPiL50/n9onXLzzw7gby87LBWbCrxc0SBqbzKoWczD+iR1/aqoKxWyXFm/enWHrp3aidFhJr8Hd5ZibMEa9Z1XfSHX3RRdESQ9ufV6DcLdumVZYdVY2f2H20Pv9XQrIb3jdbf7uqlTokhKrLW6sFXsvX6J0dovnKGrJUOPfHPfb5S6utpnNZiXTwkXr8Y61nvP2/JIa3bafVzRE0nt9imv/33oCTp6ox2Gtyr+bd5wtkJNRv1u6s7y2iUvvy+VG9+Fvhb/Lndbi34IEcbd1co1GzU/5veTfH0pGgRrhyVqMvOT5AkPZt5UN9lt80lKE3B7XZrxXclumPuTn26oUQGg3T5BQla8KveGtAj0t/hNRqDwaBR6TF66b5UjR0YK5db+u/KAs38+05t3svkE9oWEn80u07tQvXczF66aEic3G7prc/z9MDLu5VXYvd3aK1CSXmtb/1du5hg/f6aLjJRSt2iXT8+SeMGxcrlkp56c7+yDwdeo6GCUrseXrRHVTaX0rqE08W/FUvtFK47JqVIkv75WV5Al1m73W699r8jWrbWU6XywM87q0cHtp1sKQwGg26f1EGj0j19gh5/Yx+N2hrBoQKb/rBoj5759wGVVDjUKTFEz97RU3dMTlGouXXP8p9MdESQfvfzznrsl54be4eL7HpgYbaeX3JIlTVOf4cHNAsSf/hFWIhJ913ZSb+/prPCQ4zatr9KM/++U8u/KZLLxez/yRSU2fW7hdnal1ejuKggzb6xu6JbScOdtsxgMOhXV3TUgB6Rqra79OhrewJqm6r8UrseeDlbucV2Jcea9eC1Xfy+vzPOzqXnJ2j6RZ6bNy8vO6zl3wTeMhWH0605bx/Uf7I8Hfxvm9hBI9JYMtXSGI0G/XZaZ/XvFqEqm0sPvpKtLczUNkiN3aXXPzmiGc/t1HfZFTIHGTR9QrKev7e3+naJ8Hd4zWJoH4teui9VPxsaJ8nTd+rWZ3fof98WycnnTwQ4En/41ZgBsZp/b2/16RSuyhqX/v7uIT3wcnZAJUWN5UixTQ+8lK2cQpvaxQTrL7f3VJekUH+HhdMUHGTUI9d3VdekUBWXO/SbBbu0/ofWX/afV+KZNTlSbFdynFnP3N5DidFmf4eFRnDNmHa6arRnR4Z5Sw4F1BrrGrtTj72+V59uKJHRKP36io6aOpLdJ1oqc7BRj97QVb07hsla5dRDi/bosw3F/g6r1XC63Pp4XbFufXaH3vo8Tw6nW0N6R+nF+1J17dgkmYPaVjoQEWrSvVM76U+39lDHxBCVVjj0t3cO6Vfzd3FTqRVpjh40gdbnhqlC+F1yXIj+ekdPvb+6UK9/ckRb91Xq7nk/aNroRP38wiSFBLetX0gnsu9ItR55ba8Ky2rVPs6sp2/toaRYkqvWJiLUpGdu66HHF+/Tlr2VevS1vbpzSoqmjEjwd2gNcqTYpt+/nK380lp1iDfrT7eR9AcSg8Ggmy9pryqbS8vWFumv/zmgqhqXfjY0rlV3uy+tcOj//WOvdh6qUkiwQQ9d21XD+ra+zuVtTVRYkJ65raf+mnlAX20p018zD+pQoU03jE9m55CTcLvdWv9DuRZ9lKt9RzwTKu1ignXbpA66oF90q/533BgG9IjUgl+l6oPVhVr82RFlH67W7xZm6/x+0bp+XJK6tWfZT0tmMBi0akuprJVNswONJSJII/vHNMm5/YXEHy2CyWTQ1JGJuqB/tOa/l6Nvdlj11hf5+t+6Yl07NkkXD4lTcBu7Iy1JLpdb731dqFf/l6tah1udEkP09K09aDzVilkigvTUzd01b8khfbK+RC+8n6ODBTW6Y1JKqyqP/2pLqf7+7iFZq5xKSQjRn27toYRoXpeBxmAwaOalKbLZXfpsY4nmLTmk7/dU6J6pHVtlx+9VW0o1/70clVY4FBVm0mM3dlPfzm2jxDkQhJqN+sO1XfT6J0f07xX5+tcX+TqYb9Pdl3dUTCQfab3cbrfW/VCu/6zI15Z9lZKkyFCTrhnbTlOGJ8jMhIpPUN3nzwsHxuqNT45o+bdF+nprmb7eWqaR/aP1i3FJ6pbMDYCWylrpUHF529p69mzwLokWpV2MWf9velet2lKmV5YdVn5prea/l6O3vyzQdeOSNHZQbJtpZFdQatezbx/UpmxP2dl5qVH6zVWd+XATAIKDjLrvyk7qmBCiV/93RB+sLtLmvZWaeWmK+ndr2d2UK2ucemlpjj5Z7yn77t4+VLNv7M7NqABmNBr0m6s6qWtyqF79X66yvi/VrpwqPfSLLurZIdzf4Z2W0grP75JVW8okSZ3bhWjWdV3VqR3LpVobo9GgGy9urw7xIZq35JC+2lqm7/dU6JaftdeEc+Pa9Oy/0+nWys2l+k9WvvbWzfAHmQy6dESCrrmwnaLC+fxwMjGRQbpnakdden6C3vw8Tys3l2rVljKt2lKmC/pF69LzE5TeLaLNV0mgdeMdAC2Od+uVYX0t+uibYv1rRZ7ySuya8/ZBLf4sTxOHxeviIXEB29TO7nDpk/XFevWjXFXWuBQSbNRtk9pr4tB4fuEEEIPBoKvHJCklMVR/f+eg9h2p0e8WZmvcoFjd8rP2io1qeYn093sq9GzmAeWX1spgkKaNbqfrxre99aFtkdFo0FWj26lflwg9/dZ+HS6y6zcLduvnY9rp8gsSW+zsv8Pp1mcbi/V/y3NlrXLKaJR+ntFO17TBdc2B5qIhceqSFKq/v3tQe3Jr9Ld3DumTDSW6+7IUdW1jM7R5JXZ9vK5Yn6wvVkFZrSQpzGzUz4bFa+oFiVRjnYEuSaF66NouuvbCdnrr8zx9ublMX231/OmSFKopI+I1dmCswkJa5nsecCoGd6B1LThNe/fu1RNPPKH169crLCxMkyZN0m9/+1uFhjbs7v+4ceMkSZ999lljhtlklq0tbNLSmLioIE0c1jjrlmvsLn2wulCZWfkqr/ZsuRIcZNDo9Bj9bGi8+nYOD4g7/LZal/73bbEyv8xXYd0v7tSO4frt1Z3VMTHEz9E1TFO+zhrzNeZv1kqHXvs4Vx99Wyy3WwoPMeqKkYn62dB4xfl5Jt3tdmvDrgplZuVr0x5P9UlSrFm/vbqT+ndt2dUJjak1vWc2tfIqh559+6DWbvc0p4wKM+mqjHa6dER8i9kKrNrm1EffFuvdVQW+RKh7+1Ddd1WnFl2lwHvmmXM63VrydYH++WmeauwuGY3SyP4xuvyChIBexlFZ49S3O6z6eH2xvsuukPfTvCXcpMvOT9SUEfF+neEPlPfM/Xk1en91oT7bUCJbrUuSFBZi1Ii+0Rp1TrQG94riJqIfne3rzO12y+WSap1u2R0uOZxuud2S2y1Fhhl14cA4dW8f2uIn3k43D22Tib/VatXkyZPVoUMH3XXXXSouLtbTTz+tUaNG6a9//WuDzkniX19TvCHX2F368vtSLV1TqF05P+7jGxcVpPP7Rev8ftFK7xapoFa0TlqSDhfZ9OX3pXp/daFK6v6fxEUFaVqGZy1ea1r3fSw+xJ6ZnQerNP+9Q77Xt8kojUiL1uThCTqne/OWGNbYXVq7o0xvZxVo9+Ef47l4SLxu/ln7FjvD21Ra43tmU3K73craVKp/fpannEKbJE+p7JThCRp9Toxfbla63W5l51Zr1eYyfbi2SBV1N4pjo4J0xchEXXZ+QovvFcN7ZsPll9r14gc5Wr3tx91SUjuG67ILEnR+v+iAaBRcUGbX2m1Wrd5epu/3VMrh/PEj/MAekbp4SJzO7xfdItbwB9p7ZkW1U59uKNbS1YXKKbL7jkeEGjUiLVrnpVo0oEdkwFajtlTHvs7cbrdstW5V2ZyqtrlUbXOq2u6q+2+X7A6Xah1u1Trdqq3775/axfE3V3XShHPjmviZnJ3TzUPb5KvzX//6l6xWq5YsWaK4OM//SJPJpN/+9reaMWOGevTo4ecIcSKhZqMuGhKnCefGaufBKn241tOApbjcoaVrirR0TZEiQo3q1yVC/bpFqn/XCPVKCWtxH/TcbrcOFtj09VbP2rHswz/exGgXE6xpGe100blxLeIXN5pXaqdwzb2rl+8G17b9Vb41hu1igjWoZ5QG9YrUgO5RTdLrodhaq7U7rFqz3arvdpfL7vD8NgwJNuqS8+J0xahEtYuhaz88S1XGDIzVqPQYfbGpRIs/y9ORYrve+PSI3vj0iLolh2rUOTEa0deiTu1Cm6w3S7XNqZ2HqrRmm1Wrt5Upv7TW91iHeLOuGt1O4wbF8n7aBrSLMevRG7ppT261lnxVoBWbSrXzUJX+/O8DCgk2aGDPKA3tY9HQVEurKH13udw6XGTT1n2V2rq/Ulv3VerwUQmnJKUkhGh0erQmDIlT+7jWWRnYWkSGmXT5BYm6dESCdhys0pffl2rVllIVWR36dEOJPt3wY9+bQT2jlNYlQj1TwpQYHdziZ4tbA5fLLWuVU8XltSq21qqovFbFVoc27i5XSYXDk+DbXKq2u9TQKe0gk0FBJoOMBsloMCjIJCXFhqhHh8BZOtQmZ/yvv/56RUVFacGCBb5jdrtd5557ru677z7dfPPNZ3xOZvzra647sXaHS5uyKzwdWLeVyVrprPe4Ocigzu1C1SUpVJ2TQtU1KVTt48xKjAlulpJUu8Ol/JJa5RTa9MOhKu08WKWdh6p8M1GSZDRKA7pH6sKBsRozIKbF3ag4G8xenZ29udVaurZIn28sUY3dVe+xLkmh6tIuRB0TQ9UpMUQpiSGKiQhSVLhJIcHGE37QcLvdqrG7VFbpUGmFQ3mldu3NrdHeIzXad6S6XtIkeW5EjR8cp0vPT2jzsxiB8p7ZVBxOt7I2lWjFplJt3F0u51Ev1zCzUT1SwtQ7JVw9OoSpXWywEizBirMEn1aJrNvt+cBXWFargjK7covs2p1TrV2Hq3SowFbvQ15IsFFDekdpzMAYjUiLbnXNYHnPbDylFbVatrZYH31b5Fvu4ZUSb1aPutdjzw5h6poUqpjIIL8sG6yxu5Rfald+iV2HCm3an+d5Tz6QV6PqY973DQapb+dwDe8brRFpFnVMbLnNKdvCe6bL5dbW/ZX6emuZvsuu8G2ZeDRLhEk9O4SpW3KYOiSEqEO8WSnxIYq3BAfEMtWz4XK5VVnjVGmFQ6WVDt9nE+/fxeUOFVk9iX5JhaNehctPCTUbFWY2KizEqLAQk8JDjAo1GxUSbFRwkMHzx+T5b3OQJ+E/9nNTS3iNnS5m/E8hOztbV155Zb1jZrNZnTt3VnZ2tp+iQkOYg4w6L9Wi81ItuvuyjsrOrdbWfZXasq9SW/ZVyFrp1O7D1b5S5aNFhZmUGBOsuKhgRYWbFBUWJEu4SRFhJpmDjQoJMijEbJQ5yCiDQTLIM8tlMHg+5NY6XLI7PGuCqmpcKq9yyFrlVHmVQ8UVDuUV21VorT3hncfgIIPO6RapUenRGp4W3eaTKpxYt/ZhuufyjrptYntt2VupjbsrtHF3ufYeqdH+PM8fqey47wsyGRQVZqr7UFFXxuaWqmxO2WpP/YsztVO4hvW1aHgfi7omt/x1bWgZgkwGjRscp3GD41Re5dDX28q0anOZNu+tVLXdpS17K7Vlb+Vx32eJMCncbFJwsEHmIKOCTQa53G7Z/3979x4UVf3/cfy1LAvrhRUkSFN/mZqEQIozKk6iAoKVqJOVWl7KGBXxNml5+SMdv+PtD3VqUEzGUTOzUUgrx0s5ZuaMI018zdTRxEt5BVFBFOS2u78/VlC+YGqKB5bnY2YH95yzy2vXz5zzeZ/z+RzKnCouc6i0zKGbt+0qK79/u/W3earriz7q2amZwjv4yOrlPidP8e/5NrXo3Zhn9U50oP7KLlbGiQL9eqJAJ84X6eK1Ul28Vqpf/siv3N7iaVJgM4sC/bz0TDOLbI1dJ1KbNnI9rBazvCyugsHb4iGTJLvDdWLK6ZTszrtzg+0Op+x2590hxqV2FZU4VHCnuHE97Mq9UVrtgsW9LJ4mBbVp7BrJ2LaJgv+viZo2aljTrOoyDw+Twl5oqrA7f40n72aZDp++pcNnbunkhSL9nVOsgkK7/pt1S//NulXltZ5mk5r7eMrf5uqHNvfxVJNGZjWxmtX4TqHa2GpWY6uHmnib1djqOqlfcVXa02yS2UO1foyumANvdzjlcDpld+hu/7fMoZKyOz/LHSotc6rkzn67sNihwhK7iortKiy2q7DYcc+/7bp5264bheVyOB6c4V6+TT3V3MdTzX0s8rdZdL2gTDK57rvQ2NusRl6uAr+hn1S5nwZ5xT8kJERTp07VuHHjqix/55135O/vr+XLlz/ye4aFhclut6tly5ZPKmatKi51PHBOy+PwMKlOdL7sDuedIt31s/zOwfhptnqTSTJ73Dm76HnnTGM9nrf/KGqzndWVNmYEh9N14C23u9qzq23f7YA+iOnOMDYPD1fH0tPs6kxYzK4TW6iuoewza0PFPrjM7lS53SG7w3Wl51H3wx4ero6u2cPV6a3Yp7pT/459Zu1zOKXycqfK7Hfn+tof4UpibTCZJLPZJE8PU5XCrr7ds+he7DMlpyramus4XXFCqNzhdK18AiqO2a6fNbeXB7Ui5z3/une/7Ky6stZU9JM9TK79vIdHRR/Ftc+v6K/UNIKLfabL5cuXZTabdeTIkX/cjsuM93A6nf/6zJm3t7dKS0sfvGEdUV8a8uMye5hk9jDJu+5P53NLDaWdPW0eJteQZtr100Nb/vcqChjXLEmuVv4T2lnt8zBJXhaTvCy0xdpEW3YV3BXDylE7aGcunp6e8vJ68D2YGmThb7PZVFBQUG35zZs3//WN/X777bfHjQUAAAAAwBPXIE+TtG/fvtpc/tLSUp07d447+gMAAAAA3EqDLPx79+6tgwcPKi8vr3LZ7t27VVpaqj59+hiYDAAAAACAJ6tB3tyvoKBA8fHxatWqlZKSknTt2jUtXrxYvXr10pIlS4yOBwAAAADAE9MgC39JOnv2rObPn6/MzExZrVbFx8fro48+ktVad/8mKgAAAAAAj6rBFv4AAAAAADQEDXKOPwAAAAAADQWFPwAAAAAAbozCHwAAAAAAN0bhDwAAAACAG6PwBwAAAADAjVH4AwAAAADgxij8AQAAAABwYxT+DcTff/+tOXPmaPDgwerUqZPi4+ONjgRU2rlzp5KSktSnTx916dJFAwcO1MaNG+VwOIyOBlTav3+/Ro4cqYiICIWGhiomJkaLFi3SzZs3jY4GVFNYWKjevXsrKChIR44cMToOIEnasmWLgoKCqj2WLFlidDSgirS0NA0aNEhhYWHq2bOnEhMTjY702DyNDoCnIysrS/v27VPnzp3lcDjkdDqNjgRUWrt2rZ577jnNmDFD/v7+ysjI0IIFC3T+/HnNnDnT6HiAJOnGjRsKDw/Xe++9J5vNpqysLCUnJysrK0tr1qwxOh5QRUpKiux2u9ExgBqtXr1aPj4+lc+fffZZA9MAVSUnJ2vdunVKTExU586ddePGDe3fv9/oWI+Nwr+BiI6OVr9+/SRJs2bN0tGjRw1OBNz1+eefq3nz5pXPIyIiVFRUpK+++koffvihvLy8DEwHuMTHx1cZLdWjRw95eXnpk08+UU5ODh1X1BmnT5/Wxo0bNXPmTM2dO9foOEA1ISEhVY77QF1x+vRprVy5UqmpqerVq1fl8tjYWANTPRkM9W8gPDz4r0bdVdPBPzg4WCUlJcrPz3/6gYCH5OvrK0kqLy83NghwjwULFmj48OF64YUXjI4CAPXKli1b1KZNmypFv7ugGgRQJ2VmZsrX11f+/v5GRwGqsNvtKikp0bFjx7RixQpFRUWpVatWRscCJEm7du3SiRMnNHHiRKOjAPcVHx+v4OBgxcTEaNWqVUxLQZ1x+PBhdezYUStWrFDPnj0VGhqqkSNH6vjx40ZHe2wM9QdQ5xw5ckRbtmzRxIkTZTabjY4DVBEVFaWcnBxJUmRkpJYtW2ZwIsDl9u3bWrx4saZNm6amTZsaHQeoJiAgQJMnT1bnzp1lMpn0008/6dNPP1VOTo7mzJljdDxAubm5OnbsmLKysjRv3jxZLBYtX75cY8aM0Y8//iibzWZ0xH+Nwh9AnZKbm6spU6YoLCxMY8eONToOUE1qaqqKiop06tQppaSkKDExUWvXruUkFQy3cuVK+fv7a8iQIUZHAWoUGRmpyMjIyue9evWSt7e3vvjiCyUmJiowMNDAdIDkdDpVVFSk5ORkvfjii5Jc96SIiYnRpk2b6nXflKH+AOqMmzdvauzYsbJarVq5cqUsFovRkYBqXnrpJXXt2lVDhw7V8uXLlZGRod27dxsdCw3cxYsXtWbNGk2ZMkW3bt1SQUGBioqKJElFRUUqLCw0OCFQs9dee012u90thlKj/mvWrJmeeeaZyqJfkgIDA9WuXTudOnXKwGSPjyv+AOqEkpISTZgwQVevXtWmTZvk5+dndCTggYKDg2U2m3Xu3Dmjo6CBu3DhgsrKyjRu3Lhq60aPHq3OnTtr8+bNBiQDgPqjffv2unTpUrXlTqez3t8sncIfgOHKy8s1depUnThxQhs2bOBGaag3Dh06JLvdrtatWxsdBQ1ccHCw1q9fX2XZ8ePHtWjRIs2bN09hYWEGJQP+2Y4dO2Q2m9WpUyejowDq27evtm7dqpMnT6pjx46SpJycHJ05c6beT6Oi8G8gbt++rX379klyDQe8deuWdu3aJUnq3r07f0sVhvrPf/6jvXv36uOPP1ZxcbF+//33ynUdOnTgJlWoEyZNmqTQ0FAFBQXJarXqxIkTWr16tYKCgtSvXz+j46GBs9ls6tGjR43rQkJCFBIS8pQTAdUlJCQoIiKisqDas2ePNm/erNGjRysgIMDgdIAUGxurkJAQTZ48WVOnTpWXl5dWrFih5s2ba+jQoUbHeywmp9PpNDoEat+FCxcUExNT47r169fft7MAPA3R0dG6ePFijeton6grUlNTtWPHDp07d05Op1OtWrVSbGysEhISODmFOikjI0OjR49Weno6V/xRJ8yfP1/79+9Xdna2HA6H2rZtq7ffflujRo2SyWQyOh4gSbp27ZoWLlyoffv2qby8XN26ddPs2bPVrl07o6M9Fgp/AAAAAADcWP2+QwEAAAAAAPhHFP4AAAAAALgxCn8AAAAAANwYhT8AAAAAAG6Mwh8AAAAAADdG4Q8AAAAAgBuj8AcAAAAAwI15Gh0AAADUL4cPH1ZqaqqOHTumq1evymazqU2bNgoPD9esWbOMjgcAAP6Hyel0Oo0OAQAA6oeff/5ZEyZMUPfu3TV06FAFBAQoNzdXR48e1fbt2/XLL78YHREAAPwPCn8AAPDQRo4cqZycHO3cuVOenlUHDjocDnl4PJ1ZhLdv31ajRo2eyu8CAKC+Y44/AAB4aPn5+fLz86tW9EuqVvRv27ZNw4YNU3h4uMLDwzV48GClpaVV2SY9PV2DBg1SWFiYunfvrokTJ+r06dNVtpk1a5bCw8P1559/6oMPPlB4eLjef/99SVJpaalSUlL06quvKjQ0VBEREZo9e7auX7/+ZD84AAD1GHP8AQDAQ+vSpYvS0tI0f/58DRw4UJ06dZLFYqm23WeffaaUlBTFxcVpzJgx8vHxUVZWli5dulS5zapVq7Rs2TLFx8dr+vTpysvL0/LlyzVs2DClp6erbdu2lduWlZVpwoQJGj58uMaOHSu73S6Hw6GkpCRlZmYqISFBXbt21cWLF5WcnKw//vhD33zzjaxW69P4WgAAqNMY6g8AAB5aXl6eJk6cqMzMTEmSxWJRaGiooqOjNWLECDVp0kTnz59X//799frrr2vJkiU1vk9BQYEiIyPVo0cPpaamVi6/fPmy4uLiFBcXp6VLl0pyXfHfunWrFi5cqDfffLNy2+3bt2vatGlKTk5WXFxc5fIjR47orbfe0ty5c/Xuu+/WxtcAAEC9wlB/AADw0Pz8/LRx40alp6dr+vTpio6O1l9//aWlS5dq4MCBun79ug4cOCC73a4RI0bc930OHTqk4uJivfHGG1WWt2zZUhERETp48GC11/Tv37/K871798pmsykqKkrl5eWVj+DgYAUEBOjXX399Mh8aAIB6jqH+AADgkYWFhSksLEySaxj+kiVLtG7dOq1evVo+Pj6SpBYtWtz39fn5+ZKkgICAausCAwN14MCBKssaNWqkpk2bVll27do1FRQUKDQ0tMbfkZeX99CfBwAAd0bhDwAAHovFYtGkSZO0bt06ZWVlqV+/fpKk7OxstWzZssbX+Pr6SpJyc3Orrbty5Yr8/PyqLDOZTNW28/Pzk6+vr1avXl3j72jSpMmjfAwAANwWQ/0BAMBDu3LlSo3LK+7EHxgYqFdeeUVms1lff/31fd8nPDxcVqtV33//fZXl2dnZOnjwoCIiIh6YpW/fvsrPz5fD4agcgXDvo127do/wyQAAcF9c8QcAAA8tISFBLVq0UFRUlNq1ayen06njx49rzZo1aty4sUaPHq3WrVtr/PjxSklJUXFxseLj4+Xj46NTp04pLy9PU6ZMkc1mU1JSkpYtW6YZM2ZowIABys/P14oVK+Tt7a1JkyY9MMuAAQO0bds2jRs3TqNGjdLLL78si8Wi7OxsZWRkKCYmRrGxsU/hWwEAoG7jrv4AAOCh7dixQ3v27NHRo0d15coVlZWVKSAgQN26ddP48ePVvn37ym2//fZbbdiwQSdPnpTZbFbbtm01atQoDRkypHKbtLQ0ffnllzpz5oysVqu6d++uadOmqUOHDpXbzJo1Sz/88IMOHTpULU95ebnWr1+v7777TmfPnpXZbFaLFi3UrVs3JSQk6Pnnn6/dLwQAgHqAwh8AAAAAADfGHH8AAAAAANwYhT8AAAAAAG6Mwh8AAAAAADdG4Q8AAAAAgBuj8AcAAAAAwI1R+AMAAAAA4MYo/AEAAAAAcGMU/gAAAAAAuDEKfwAAAAAA3BiFPwAAAAAAbozCHwAAAAAAN0bhDwAAAACAG/t/rEJTfvaE/iQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(\"/home/jovyan/AES/train.csv\", sep=',', encoding='ISO-8859-1')\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = df.sample(frac=1, random_state=1337)  # Added random_state for reproducibility\n",
    "\n",
    "# Verify column names\n",
    "print(f\"Columns in the dataset: {df.columns}\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Set the style for the plots\n",
    "sns.set(color_codes=True)\n",
    "sns.set(style=\"white\", palette=\"muted\")\n",
    "\n",
    "def plot_distribution(df, target_col):\n",
    "    \"\"\"\n",
    "    Shows distribution\n",
    "    \"\"\"\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Column '{target_col}' not found in DataFrame columns: {df.columns}\")\n",
    "        return\n",
    "    \n",
    "    df = df[[target_col]]\n",
    "    print([df[i].value_counts()/len(df)*100 for i in df.columns])\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(df[target_col], kde=True)\n",
    "    plt.title('Distribution of Scores')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    \n",
    "    df.hist(figsize=(10, 7))\n",
    "    plt.show()\n",
    "\n",
    "# Plot the distribution\n",
    "plot_distribution(df, 'score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:40:01.572256Z",
     "iopub.status.busy": "2024-06-02T09:40:01.571662Z",
     "iopub.status.idle": "2024-06-02T09:40:01.880724Z",
     "shell.execute_reply": "2024-06-02T09:40:01.879780Z",
     "shell.execute_reply.started": "2024-06-02T09:40:01.572210Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the training dataset: Index(['essay_id', 'full_text', 'score'], dtype='object')\n",
      "Columns in the test dataset: Index(['essay_id', 'full_text'], dtype='object')\n",
      "Training Dataset:\n",
      "  essay_id  \\\n",
      "0  000d118   \n",
      "1  000fe60   \n",
      "2  001ab80   \n",
      "3  001bdc0   \n",
      "4  002ba53   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \\\n",
      "0  Many people have car where they live. The thing they don't know is that when you use a car alot of thing can happenÂ like you can get in accidet orÂ the smoke that the car has is bad to breathÂ on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban's families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbiddenÂ on the outskirts of freiburd that near the French and Swiss borders. You probaly won't see a car in Vauban's streets because they are completely \"car free\" butÂ If some that liv...   \n",
      "1  I am a scientist at NASA that is discussing the \"face\" on mars. I will be explaining how the \"face\" is a land form. By sharing my information about this isue i will tell you just that.\\n\\nFirst off, how could it be a martions drawing. There is no plant life on mars as of rite now that we know of, which means so far as we know it is not possible for any type of life. That explains how it could not be made by martians. Also why and how would a martion build a face so big. It just does not make any since that a martian did this.\\n\\nNext, why it is a landform. There are many landforms that are...   \n",
      "2  People always wish they had the same technology that they have seen in movies, or the best new piece of technology that is all over social media. However, nobody seems to think of the risks that these kinds of new technologies may have. Cars have been around for many decades, and now manufacturers are starting to get on the bandwagon and come up with the new and improved technology that they hope will appeal to everyone. As of right now, it seems as though the negative characteristics of these cars consume the positive idea that these manufacturers have tried to convey.\\n\\nCurrently, this ...   \n",
      "3  We all heard about Venus, the planet without almost oxygen with earthquakes, erupting volcanoes and temperatures average over 800 degrees Fahrenheit but what if scientist project the futur into this planet ? Through this article, the author uses evidences appealing to reason and concession to make us realize why we should care about studying this planet so that people must give a chance to Venus.\\n\\nVenus is the closest planet to Earth in terms density and size but has a really different climate. As it is evoked by the author:\\n\\n( 3) \"A thick atmosphere of almost 97 percent carbon dioxide...   \n",
      "4  Dear, State Senator\\n\\nThis is a letter to argue in favor of keeping the Electoral College.\"There are many reasons to keep the Electoral College\" one reason is because it is widely regarded as an anachronism, a dispute over the outcome of an Electoral College vote is possible, but it is less likely than a dispute over the popular vote, and the Electoral College restores some of the weight in the political balance that large states (by population) lose by virue of the mal apportionment of the Senate decreed in the Constitution.\\n\\nI am in favor of keeping the Electoral College because,it is...   \n",
      "\n",
      "   score  \n",
      "0      3  \n",
      "1      3  \n",
      "2      4  \n",
      "3      4  \n",
      "4      3  \n",
      "Test Dataset:\n",
      "  essay_id  \\\n",
      "0  000d118   \n",
      "1  000fe60   \n",
      "2  001ab80   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \n",
      "0  Many people have car where they live. The thing they don't know is that when you use a car alot of thing can happenÂ like you can get in accidet orÂ the smoke that the car has is bad to breathÂ on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban's families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbiddenÂ on the outskirts of freiburd that near the French and Swiss borders. You probaly won't see a car in Vauban's streets because they are completely \"car free\" butÂ If some that liv...  \n",
      "1  I am a scientist at NASA that is discussing the \"face\" on mars. I will be explaining how the \"face\" is a land form. By sharing my information about this isue i will tell you just that.\\n\\nFirst off, how could it be a martions drawing. There is no plant life on mars as of rite now that we know of, which means so far as we know it is not possible for any type of life. That explains how it could not be made by martians. Also why and how would a martion build a face so big. It just does not make any since that a martian did this.\\n\\nNext, why it is a landform. There are many landforms that are...  \n",
      "2  People always wish they had the same technology that they have seen in movies, or the best new piece of technology that is all over social media. However, nobody seems to think of the risks that these kinds of new technologies may have. Cars have been around for many decades, and now manufacturers are starting to get on the bandwagon and come up with the new and improved technology that they hope will appeal to everyone. As of right now, it seems as though the negative characteristics of these cars consume the positive idea that these manufacturers have tried to convey.\\n\\nCurrently, this ...  \n",
      "Index(['essay_id', 'full_text', 'score'], dtype='object')\n",
      "3    36.285896\n",
      "2    27.289536\n",
      "4    22.684463\n",
      "1     7.234067\n",
      "5     5.604669\n",
      "6     0.901369\n",
      "Name: score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to set the random seed for reproducibility\n",
    "def seed_all(seed_value):\n",
    "    \"\"\"\n",
    "    Setting the random seed across the pipeline\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    random.seed(seed_value) \n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 1337\n",
    "seed_all(seed)\n",
    "\n",
    "# Read the datasets\n",
    "train_df = pd.read_csv(\"/home/jovyan/AES/train.csv\", sep=',', encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv(\"/home/jovyan/AES/test.csv\", sep=',', encoding='ISO-8859-1')\n",
    "\n",
    "# Verify column names\n",
    "print(f\"Columns in the training dataset: {train_df.columns}\")\n",
    "print(f\"Columns in the test dataset: {test_df.columns}\")\n",
    "\n",
    "# Display the first few rows of the datasets\n",
    "print(\"Training Dataset:\")\n",
    "print(train_df.head())\n",
    "print(\"Test Dataset:\")\n",
    "print(test_df.head())\n",
    "\n",
    "\n",
    "# Set the style for the plots\n",
    "sns.set(color_codes=True)\n",
    "sns.set(style=\"white\", palette=\"muted\")\n",
    "\n",
    "def plot_distribution(df, target_col):\n",
    "    \"\"\"\n",
    "    Shows distribution\n",
    "    \"\"\"\n",
    "    print(df.columns)\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Column '{target_col}' not found in DataFrame columns: {df.columns}\")\n",
    "        return\n",
    "    \n",
    "    df = df[[target_col]]\n",
    "    distribution = df[target_col].value_counts(normalize=True) * 100\n",
    "    print(distribution)\n",
    "    \n",
    "\n",
    "# Plot the distribution\n",
    "plot_distribution(train_df, 'score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:40:06.959140Z",
     "iopub.status.busy": "2024-06-02T09:40:06.958428Z",
     "iopub.status.idle": "2024-06-02T09:40:07.657350Z",
     "shell.execute_reply": "2024-06-02T09:40:07.656496Z",
     "shell.execute_reply.started": "2024-06-02T09:40:06.959095Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the training dataset: Index(['essay_id', 'full_text', 'score'], dtype='object')\n",
      "Columns in the test dataset: Index(['essay_id', 'full_text'], dtype='object')\n",
      "KS test result: statistic=0.00045730933872401014, p-value=1.0\n",
      "3    36.285896\n",
      "2    27.289536\n",
      "4    22.684463\n",
      "1     7.234067\n",
      "5     5.604669\n",
      "6     0.901369\n",
      "Name: score, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA08AAAJfCAYAAACnn+01AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9AUlEQVR4nO3df5TWdZ338dfwY2AURsNQbikVcSEGiWBXwT3qGMbuSaFkudXaiBaBbpRVT2uWm8gexCy3ZJYlwB2ldjW6Mzpq9+2RTp3MWTodvc+GecpfKyOEEQFWOvwYZ/hx3X94mJwG5XsBeQ3xeJzjGee6Ptd33jN+nJnn9b2ua6pKpVIpAAAAvKUelR4AAADgaCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAKKi1tbXSIwBQQeIJgKPGb3/729xyyy2pr6/P2WefnfHjx+cjH/lIfvzjH3es+c///M984hOfyJ//+Z9n9OjR+eAHP5h/+7d/63ScH/zgB7nyyiszevTojBkzJjNmzMiTTz7Zac2SJUsyfPjwPP3007nuuutyzjnnZOLEiUmSUqmUlStX5sMf/nDe+9735pxzzsl1112Xl1566Y//RQCgYnpVegAAKOrGG2/MM888k0996lM544wz0tLSkmeeeSavvPJKkmTVqlW55ZZbcs4552TBggU56aSTsn79+rzwwgsdx/i///f/5tOf/nTOP//83HnnnWlvb88999yTj3/84/n3f//3/MVf/EWnj3nttdfmkksuyUc+8pHs2rUrSTJ//vw8+OCD+fjHP55Pf/rTefXVV7N06dJ85CMfyXe+8528853vfNu+JgC8fapKpVKp0kMAQBFjxozJ5Zdfns997nNdrtu5c2cuvPDCDB8+PCtXrkxVVVWXNfv27Ut9fX1OPPHEfOc730mPHj06bjtx4sScdtpp+eY3v5nk9TNPX/nKVzJ37txcd911Hcf46U9/miuvvDI33XRTZsyY0XH5r3/96/z1X/91pk2blhtvvPFIf+oAdAMetgfAUeO9731vHnzwwSxbtiw//elPs3v37o7rnnzyyezYsSN/+7d/e8BwSpL169dn69at+fCHP9wRTkly/PHH56/+6q/y1FNPdXle01/91V91ev+HP/xhqqqq8qEPfSh79uzp+Oed73xn3vOe9+T//b//dwQ/YwC6Ew/bA+Co0dDQkOXLl+fb3/52Fi9enOOOOy4TJ07MjTfemN/+9rdJkkGDBr3p7X/3u98lSQYOHNjlupNPPjn79u1LS0tLampqOl3+Rr/5zW9SKpXyl3/5lwf8GO9+97vL/rwAODqIJwCOGgMGDMjNN9+cm2++Ob/61a/y6KOP5s4778xvfvObjofQ/frXv37T27/jHe9Ikmzbtq3LdVu3bk2PHj1SW1v7ljO84x3vSFVVVVauXJnq6uou1x/oMgD+NHjYHgBHpVNPPTXTpk3LX/7lX+aZZ57JmDFj0r9//3zzm9/Mmz2dd8iQITnllFPy8MMPd1qza9eufO9738v73ve+TmedDuSiiy5KqVTKli1bMmrUqC7/DB8+/Ih+ngB0H848AXBU2L59e6ZPn55JkyblzDPPzPHHH5+f/exnWbNmTSZOnJjjjz8+n/3sZzNv3rz83d/9Xa644oqcdNJJ2bhxY5577rnMnz8/PXr0yI033phPf/rT+V//63/lyiuvTHt7e1asWJGWlpbccMMNB53jz//8z3PllVfmc5/7XH7+85/nnHPOSU1NTbZt25af/OQnGTZsWP72b//2bfiKAPB2E08AHBX69OmT9773vfnOd76TTZs2Zc+ePfkf/+N/ZPbs2Zk1a1aS5PLLL8/JJ5+ce+65J/PmzUupVMrgwYNz2WWXdRxn8uTJqampSWNjYz71qU+lZ8+eGT16dO69996MHTu20Cy33nprRo8enfvvvz//+3//7+zbty8nn3xyxo4dm/e+971/jE8fgG7AS5UDAAAU4DlPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAo4Jj8O09/8Rd/kfb29gwcOLDSowAAABW0bdu2VFdX57/+678OuvaYPPPU1taWPXv2VHqMJEmpVEpbW1v8uS2Ksmcolz1DuewZymXPUK7utGf27NmTtra2QmuPyTNPJ598cpLkBz/4QYUnSXbt2pVnn302I0aMyHHHHVfpcTgK2DOUy56hXPYM5bJnKFd32jMXX3xx4bXH5JknAACAcoknAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8ARwDevfunaqqqkqPAQBHtV6VHgCAP66qqqrU1Y1Mr149Kz1Kt7RvXyk9eghLAA5OPAEcA3r16pl/vv8X2bi1rdKjdCunndwnn7ny9EqPAcBRQjwBHCM2bm1L869aKz0GABy1POcJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgAIOKZ5WrVqVD33oQxk1alTOO++8zJkzp9P1TU1NueyyyzJq1KhMnDgxK1euPOBxVqxYkQkTJmTUqFGZOnVqnnjiiS5rduzYkfnz52fcuHEZM2ZM5syZk02bNh3K2AAAAIes7HhasmRJvvjFL2by5MlZsWJFbr311px88skd1z/55JO55pprUldXl7vvvjtTpkzJbbfdllWrVnU6zooVK9LQ0JCPfexjaWxszOmnn57Zs2fn+eef77TuhhtuyKOPPppbbrklDQ0N2bp1a2bMmJHXXnvtED9lAACA8vUqZ3Fzc3OWL1+exsbGnH/++R2XT5w4sePfly5dmrq6utx+++1JkvHjx2fz5s1ZvHhxpk6dmh49eqS9vT3Lly/P9OnTM3PmzCTJueeem8mTJ+euu+5KQ0NDkuSpp57KY489lsbGxtTX1ydJhg0blokTJ+bBBx/MRz/60cP77AEAAAoq68zTAw88kHe/+92dwumN2tvb8/jjj+fSSy/tdPnkyZOzbdu2PPPMM0mStWvXZvv27Zk0aVLHmp49e+aSSy5JU1NTSqVSktcf/ldbW5sLL7ywY92pp56asWPHpqmpqZzRAQAADktZZ56eeuqpDBs2LEuXLs3Xv/71bN++Pe973/ty8803Z8SIEdm4cWN2796dM888s9PtzjrrrCSvn7k6++yz09zcnCRd1g0dOjQ7d+7Mli1bMmjQoDQ3N2fIkCGpqqrqcrwf/ehHZX+yb1QqlbJr167DOsaR0Nra2uktHIw9Q7na29tTU1NT6TG6tdbW1o477vB9hvLZM5SrO+2ZUqnUpTfeTFnxtG3btjz99NN54YUXsmDBgvTu3Ttf+cpXMmPGjHzve9/Lq6++miSpra3tdLv97++/vqWlJdXV1enbt2+ndSeccEKS5JVXXsmgQYPS0tKS/v37d5mjtra241iHqr29Pc8+++xhHeNI2rBhQ6VH4Chjz1BUTU1NTjzxxEqP0a2tX7++W/wA7258n6Fc9gzl6g57pr29PX369Cm0tqx42n+2ZsmSJfmzP/uzJMnIkSNz8cUX5/7778/YsWOT5E3L7Y2XH2jN/nv9DrburS4vqrq6OiNGjDisYxwJra2t2bBhQ8444wz3DFOIPUO52tvbKz1CtzdkyBBnnt7A9xnKZc9Qru60Z6qrqwuvLSueTjjhhLzzne/sCKckOfnkk3PmmWdm3bp1ef/7358kXc4KtbS0JPn9Gaja2tq0tbWlra2tU+XtX7f/DFRtbW02b97cZY6WlpYuZ7fKVVVVleOOO+6wjnEk1dTUdKt56P7sGYo63DubjgWV/sHdXfk+Q7nsGcrVHfZMOT8ny3rBiKFDhx7w8lKplB49euS0005L79698+KLL3a6ft26dZ1uv//t/uc+7dfc3Jzjjz8+p5xySse69evXd7k3cN26dW86CwAAwB9DWfF00UUX5eWXX85///d/d1y2ZcuWvPjiixk+fHiqq6szfvz4rF69utPtHn744QwcODB1dXVJkrFjx6Z///555JFHOtbs3bs3q1evTn19fUf91dfXp6WlJWvWrOlYt3nz5qxdu7bjpcsBAADeDmU9bG/ixIkZOXJkrr322lx//fWprq7O0qVLM2DAgFxxxRVJkrlz52batGmZN29eJk+enLVr12bVqlW59dZb06PH661WXV2dq6++Og0NDRkwYEDq6uqyatWqvPTSS1m0aFHHxxs9enQuuuii3HzzzbnpppvSr1+/LF68OIMHD86UKVOO4JcBAADgrZUVTz179szdd9+d22+/PfPnz8+ePXtyzjnn5M477+x4rOKYMWOybNmyLFq0KA899FAGDRqUefPm5fLLL+90rKuuuiqlUin33XdfXn755QwbNiyNjY0ZPnx4p3V33nln7rjjjixYsCC7d+/OuHHjsmTJki6v1AcAAPDHVFY8JclJJ52UO++88y3X1NfXH/RhdVVVVZk1a1ZmzZr1luv69euXhQsXZuHCheWOCgAAcMSU9ZwnAACAY5V4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWUFU8PPPBAhg8f3uWfL3/5y53WNTU15bLLLsuoUaMyceLErFy58oDHW7FiRSZMmJBRo0Zl6tSpeeKJJ7qs2bFjR+bPn59x48ZlzJgxmTNnTjZt2lTO2AAAAIet16Hc6J577kn//v073j/llFM6/v3JJ5/MNddckw9/+MO56aabsnbt2tx2222prq7O5Zdf3rFuxYoVaWhoyKc+9anU1dVl1apVmT17dlatWpXhw4d3rLvhhhvy9NNP55Zbbkm/fv3yr//6r5kxY0b+z//5P+nbt++hjA8AAFC2Q4qnkSNHZsCAAQe8bunSpamrq8vtt9+eJBk/fnw2b96cxYsXZ+rUqenRo0fa29uzfPnyTJ8+PTNnzkySnHvuuZk8eXLuuuuuNDQ0JEmeeuqpPPbYY2lsbEx9fX2SZNiwYZk4cWIefPDBfPSjHz2U8QEAAMp2RJ/z1N7enscffzyXXnppp8snT56cbdu25ZlnnkmSrF27Ntu3b8+kSZM61vTs2TOXXHJJmpqaUiqVkrz+8L/a2tpceOGFHetOPfXUjB07Nk1NTUdydAAAgLd0SGeeJk2alN/97nc59dRTc8UVV2TWrFnp2bNnNm7cmN27d+fMM8/stP6ss85KkjQ3N+fss89Oc3NzknRZN3To0OzcuTNbtmzJoEGD0tzcnCFDhqSqqqrL8X70ox8dyugdSqVSdu3adVjHOBJaW1s7vYWDsWcoV3t7e2pqaio9RrfW2tracccdvs9QPnuGcnWnPVMqlbr0xpspK54GDhyYa6+9NqNHj05VVVUeffTR/Mu//Eu2bNmS+fPn59VXX02S1NbWdrrd/vf3X9/S0pLq6uouz1k64YQTkiSvvPJKBg0alJaWlk7PrXrj8fYf61C1t7fn2WefPaxjHEkbNmyo9AgcZewZiqqpqcmJJ55Y6TG6tfXr13eLH+Ddje8zlMueoVzdYc+0t7enT58+hdaWFU8XXHBBLrjggo73zz///PTp0yf/8R//kTlz5nRc/mbl9sbLD7Rm/71+B1v3VpcXVV1dnREjRhzWMY6E1tbWbNiwIWeccYZ7hinEnqFc7e3tlR6h2xsyZIgzT2/g+wzlsmcoV3faM9XV1YXXHtLD9t7ogx/8YL761a/m2WefzeDBg5Oky1mhlpaWJL8/A1VbW5u2tra0tbV1qrz96/afgaqtrc3mzZu7fMyWlpYuZ7fKVVVVleOOO+6wjnEk1dTUdKt56P7sGYo63DubjgWV/sHdXfk+Q7nsGcrVHfZMOT8nj+gLRpx22mnp3bt3XnzxxU6Xr1u3Lsnrz2l649v9z33ar7m5Occff3zHS58PHTo069ev73Jv4Lp16zqOAQAA8HY47Hh65JFH0rNnz9TV1aW6ujrjx4/P6tWrO615+OGHM3DgwNTV1SVJxo4dm/79++eRRx7pWLN3796sXr069fX1HfVXX1+flpaWrFmzpmPd5s2bs3bt2o6XLgcAAHg7lPWwvZkzZ2b8+PEZNmxYkuQHP/hBvvWtb2X69OkZOHBgkmTu3LmZNm1a5s2bl8mTJ2ft2rVZtWpVbr311vTo8XqrVVdX5+qrr05DQ0MGDBjQ8UdyX3rppSxatKjj440ePToXXXRRbr755tx0003p169fFi9enMGDB2fKlClH6msAAABwUGXF05AhQ/Ltb387v/71r7Nv376cccYZ+dznPpePf/zjHWvGjBmTZcuWZdGiRXnooYcyaNCgzJs3L5dffnmnY1111VUplUq577778vLLL2fYsGFpbGzM8OHDO6278847c8cdd2TBggXZvXt3xo0blyVLlnR5pT4AAIA/prLiad68eYXW1dfXH/RhdVVVVZk1a1ZmzZr1luv69euXhQsXZuHChYXnBAAAONKO6AtGAAAA/KkSTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHiCo1Dv3r1TVVVV6TEAAI4pvSo9AFCeqqqq1NWNTK9ePSs9Sre0b18pPXoISwDgyBNPcBTq1atn/vn+X2Tj1rZKj9KtnHZyn3zmytMrPQYA8CdKPMFRauPWtjT/qrXSYwAAHDM85wkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFDAYcXTzp07c+GFF2b48OH52c9+1um6pqamXHbZZRk1alQmTpyYlStXHvAYK1asyIQJEzJq1KhMnTo1TzzxRJc1O3bsyPz58zNu3LiMGTMmc+bMyaZNmw5ndAAAgLIcVjwtW7Yse/fu7XL5k08+mWuuuSZ1dXW5++67M2XKlNx2221ZtWpVp3UrVqxIQ0NDPvaxj6WxsTGnn356Zs+eneeff77TuhtuuCGPPvpobrnlljQ0NGTr1q2ZMWNGXnvttcMZHwAAoLBDjqfm5uZ84xvfyLXXXtvluqVLl6auri633357xo8fn2uuuSb/83/+zyxevDj79u1LkrS3t2f58uWZPn16Zs6cmfPOOy9f+tKX8q53vSt33XVXx7GeeuqpPPbYY/n85z+fSZMm5aKLLspXvvKVbNq0KQ8++OChjg8AAFCWQ46nz3/+8/nIRz6SIUOGdLq8vb09jz/+eC699NJOl0+ePDnbtm3LM888kyRZu3Zttm/fnkmTJnWs6dmzZy655JI0NTWlVColef3hf7W1tbnwwgs71p166qkZO3ZsmpqaDnV8AACAshxSPH33u9/Nc889l7lz53a5buPGjdm9e3fOPPPMTpefddZZSV4/Y/XGt3+4bujQodm5c2e2bNnSsW7IkCGpqqrqcrz9xwAAAPhj61XuDVpbW/PFL34x//AP/5B+/fp1uf7VV19NktTW1na6fP/7+69vaWlJdXV1+vbt22ndCSeckCR55ZVXMmjQoLS0tKR///5dPk5tbW3HsQ5FqVTKrl27Dvn2R0pra2unt3Aw7e3tqampqfQY3Vpra2vH2WvsmSLsmc78bKJc9gzl6k57plQqdTlR82bKjqfly5fnpJNOyt/8zd+85bo3G+CNlx9ozf4fXgdb91aXF9He3p5nn332kG9/pG3YsKHSI3CUqKmpyYknnljpMbq19evXd4tvxt2FPXNw9syB+dlEuewZytUd9kx7e3v69OlTaG1Z8bRp06Z89atfzdKlS7Njx44k6Th7s2vXruzcubPjzNEfnhVqaWlJ8vszULW1tWlra0tbW1unYfev23+c2trabN68ucssLS0tXc5ulaO6ujojRow45NsfKa2trdmwYUPOOOMM9wxTSHt7e6VH6PaGDBniLMIb2DMHZ8905mcT5bJnKFd32jPV1dWF15YVT7/85S+ze/fufPKTn+xy3fTp0zN69Oh8/etfT+/evfPiiy92epGHdevWJXn9OU1vfNvc3Jy6urqOdc3NzTn++ONzyimndKz78Y9/3OV02rp16zqOcSiqqqpy3HHHHfLtj7SamppuNQ/d1+GccT1WVPqbcHdjzxycPXNgfjZRLnuGcnWHPVPOz8myXjBixIgRuffeezv984//+I9JkgULFuSf/umfUl1dnfHjx2f16tWdbvvwww9n4MCBHaE0duzY9O/fP4888kjHmr1792b16tWpr6/v+CTq6+vT0tKSNWvWdKzbvHlz1q5dm/r6+nLGBwAAOGRlnXmqra3NuHHjDnjdyJEjM3LkyCTJ3LlzM23atMybNy+TJ0/O2rVrs2rVqtx6663p0eP1Xquurs7VV1+dhoaGDBgwIHV1dVm1alVeeumlLFq0qOO4o0ePzkUXXZSbb745N910U/r165fFixdn8ODBmTJlyqF+3gAAAGUp+wUjihgzZkyWLVuWRYsW5aGHHsqgQYMyb968XH755Z3WXXXVVSmVSrnvvvvy8ssvZ9iwYWlsbMzw4cM7rbvzzjtzxx13ZMGCBdm9e3fGjRuXJUuWdHmlPgDgyOjdu7eHfAL8gcOOp3HjxuX555/vcnl9ff1BH1ZXVVWVWbNmZdasWW+5rl+/flm4cGEWLlx4WLMCAAdXVVWVurqR6dWrZ6VH6Zb27SulRw9hCceiP8qZJwDg6NarV8/88/2/yMatbZUepVs57eQ++cyVp1d6DKBCxBMAcEAbt7al+Vf+/hXAfmW92h4AAMCxSjwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAACigrntasWZNp06Zl/PjxOfvss3PxxRfnC1/4QrZv395pXVNTUy677LKMGjUqEydOzMqVKw94vBUrVmTChAkZNWpUpk6dmieeeKLLmh07dmT+/PkZN25cxowZkzlz5mTTpk3ljA0AAHDYyoqnV199NWPGjMnChQuzYsWKzJgxIw899FCuv/76jjVPPvlkrrnmmtTV1eXuu+/OlClTctttt2XVqlWdjrVixYo0NDTkYx/7WBobG3P66adn9uzZef755zutu+GGG/Loo4/mlltuSUNDQ7Zu3ZoZM2bktddeO4xPGwAAoDy9ylk8adKkTJo0qeP9cePGpbq6Orfccku2bNmSU045JUuXLk1dXV1uv/32JMn48eOzefPmLF68OFOnTk2PHj3S3t6e5cuXZ/r06Zk5c2aS5Nxzz83kyZNz1113paGhIUny1FNP5bHHHktjY2Pq6+uTJMOGDcvEiRPz4IMP5qMf/egR+SIAAAAczGE/5+nEE09MkuzZsyft7e15/PHHc+mll3ZaM3ny5Gzbti3PPPNMkmTt2rXZvn17pxDr2bNnLrnkkjQ1NaVUKiV5/eF/tbW1ufDCCzvWnXrqqRk7dmyampoOd3QAAIDCDime9u7dm7a2tjz99NNZunRp3v/+92fw4MHZuHFjdu/enTPPPLPT+rPOOitJ0tzc3OntH64bOnRodu7cmS1btnSsGzJkSKqqqrocb/8xAAAA3g5lPWxvv/e///0dgXPBBRdk0aJFSV5/TlSS1NbWdlq///3917e0tKS6ujp9+/bttO6EE05IkrzyyisZNGhQWlpa0r9//y4fv7a2tuNYh6pUKmXXrl2HdYwjobW1tdNbOJj29vbU1NRUeoxurbW1teMMNvZMEfZMZ/bMwdkznfl9hnJ1pz1TKpW6nKx5M4cUT42Njdm1a1fWrVuXZcuWZc6cOfna177Wcf2bffA3Xn6gNfu/CR1s3VtdXlR7e3ueffbZwzrGkbRhw4ZKj8BRoqampuPhshzY+vXru8U34+7Cnjk4e6Yze+bg7JkD8/sM5eoOe6a9vT19+vQptPaQ4uk973lPkmTs2LGpq6vL1KlT8/3vf7/j4Xl/eFaopaUlye/PQNXW1qatrS1tbW2dBt2/bv8ZqNra2mzevLnLx29paelydqtc1dXVGTFixGEd40hobW3Nhg0bcsYZZ7iXj0La29srPUK3N2TIEPcIv4E9c3D2TGf2zMHZM535fYZydac9U11dXXjtIcXTG40YMSI9e/bMxo0bM2HChPTu3Tsvvvhipxd5WLduXZLXn9P0xrfNzc2pq6vrWNfc3Jzjjz8+p5xySse6H//4x11Opa1bt67jGIeqqqoqxx133GEd40iqqanpVvPQfR3uWddjQaW/CXc39szB2TOd2TMHZ88cmN9nKFd32DPlfM877Ffbe/LJJ7N37968613vSnV1dcaPH5/Vq1d3WvPwww9n4MCBHaE0duzY9O/fP4888kjHmr1792b16tWpr6/v+ATq6+vT0tKSNWvWdKzbvHlz1q5d2/HS5QAAAG+Hss48/f3f/33OPvvsDB8+PH379s1zzz2Xe+65J8OHD88HPvCBJMncuXMzbdq0zJs3L5MnT87atWuzatWq3HrrrenR4/VWq66uztVXX52GhoYMGDAgdXV1WbVqVV566aWOF59IktGjR+eiiy7KzTffnJtuuin9+vXL4sWLM3jw4EyZMuUIfhkAAADeWlnx9N73vjePPPJIGhsbUyqVMnjw4FxxxRWZOXNmx2MFx4wZk2XLlmXRokV56KGHMmjQoMybNy+XX355p2NdddVVKZVKue+++/Lyyy9n2LBhaWxszPDhwzutu/POO3PHHXdkwYIF2b17d8aNG5clS5Z0eaU+AACAP6ay4umTn/xkPvnJTx50XX19/UEfVldVVZVZs2Zl1qxZb7muX79+WbhwYRYuXFjOqAAAAEfUYT/nCQAA4FggngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEABZcXT6tWrc80116S+vj7ve9/7Mnny5HzjG9/Ivn37Oq1ramrKZZddllGjRmXixIlZuXLlAY+3YsWKTJgwIaNGjcrUqVPzxBNPdFmzY8eOzJ8/P+PGjcuYMWMyZ86cbNq0qZyxAQAADltZ8fS1r30t1dXV+cxnPpO77rorH/jAB/L5z38+X/rSlzrWPPnkk7nmmmtSV1eXu+++O1OmTMltt92WVatWdTrWihUr0tDQkI997GNpbGzM6aefntmzZ+f555/vtO6GG27Io48+mltuuSUNDQ3ZunVrZsyYkddee+0wPm0AAIDy9Cpn8V133ZUBAwZ0vD9+/Pjs2rUrK1euzKc+9alUV1dn6dKlqaury+23396xZvPmzVm8eHGmTp2aHj16pL29PcuXL8/06dMzc+bMJMm5556byZMn56677kpDQ0OS5Kmnnspjjz2WxsbG1NfXJ0mGDRuWiRMn5sEHH8xHP/rRI/JFAAAAOJiyzjy9MZz2GzFiRNra2vLKK6+kvb09jz/+eC699NJOayZPnpxt27blmWeeSZKsXbs227dvz6RJkzrW9OzZM5dcckmamppSKpWSvP7wv9ra2lx44YUd60499dSMHTs2TU1N5YwOAABwWMo683QgP/nJT3LiiSfmpJNOyvr167N79+6ceeaZndacddZZSZLm5uacffbZaW5uTpIu64YOHZqdO3dmy5YtGTRoUJqbmzNkyJBUVVV1Od6PfvSjw5q7VCpl165dh3WMI6G1tbXTWziY9vb21NTUVHqMbq21tbXjThjsmSLsmc7smYOzZzrz+wzl6k57plQqdemNN3NY8fSzn/0sDzzwQObOnZuePXvm1VdfTZLU1tZ2Wrf//f3Xt7S0pLq6On379u207oQTTkiSvPLKKxk0aFBaWlrSv3//Lh+3tra241iHqr29Pc8+++xhHeNI2rBhQ6VH4ChRU1OTE088sdJjdGvr16/vFt+Muwt75uDsmc7smYOzZw7M7zOUqzvsmfb29vTp06fQ2kOOp23btuW6667LqFGjMnv27E7XvVm5vfHyA63Zfw/Owda91eVFVVdXZ8SIEYd1jCOhtbU1GzZsyBlnnOFePgppb2+v9Ajd3pAhQ9wj/Ab2zMHZM53ZMwdnz3Tm9xnK1Z32THV1deG1hxRP27dvz+zZs9O3b98sX748vXv3TvL7M0d/eFaopaUlye/PQNXW1qatrS1tbW2dKm//uv3Hqa2tzebNm7t8/JaWli5nt8pVVVWV44477rCOcSTV1NR0q3novg73joNjQaW/CXc39szB2TOd2TMHZ88cmN9nKFd32DPlfM8r+4/ktrW15eqrr87LL7+ce+65J+94xzs6rjvttNPSu3fvvPjii51us27duiSvP6fpjW/3P/dpv+bm5hx//PE55ZRTOtatX7++yz0769at6zgGAADA26GseNqzZ0+uv/76PPfcc7nnnnsyePDgTtdXV1dn/PjxWb16dafLH3744QwcODB1dXVJkrFjx6Z///555JFHOtbs3bs3q1evTn19fUf91dfXp6WlJWvWrOlYt3nz5qxdu7bjpcsBAADeDmU9bO/WW2/ND3/4w9x444157bXX8tOf/rTjurPOOiv9+vXL3LlzM23atMybNy+TJ0/O2rVrs2rVqtx6663p0eP1Vquurs7VV1+dhoaGDBgwIHV1dVm1alVeeumlLFq0qOOYo0ePzkUXXZSbb745N910U/r165fFixdn8ODBmTJlypH5CgAAABRQVjztf3nwL33pS12uu/feezNu3LiMGTMmy5Yty6JFi/LQQw9l0KBBmTdvXi6//PJO66+66qqUSqXcd999efnllzNs2LA0NjZm+PDhndbdeeedueOOO7JgwYLs3r0748aNy5IlS7q8Uh8AAMAfU1nx9OijjxZaV19ff9CH1VVVVWXWrFmZNWvWW67r169fFi5cmIULFxaeEwAA4Egr+wUjAAAAjkXiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8dQO9e/dOVVVVpccAAADeQq9KD3Csq6qqSl3dyPTq1bPSo3RL+/aV0qOHsAQAoPLEUzfQq1fP/PP9v8jGrW2VHqVbOe3kPvnMladXegwAAEginrqNjVvb0vyr1kqPAQAAvAnPeQIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsqOp1/84heZP39+PvzhD6euri6TJk064LqmpqZcdtllGTVqVCZOnJiVK1cecN2KFSsyYcKEjBo1KlOnTs0TTzzRZc2OHTsyf/78jBs3LmPGjMmcOXOyadOmckcHAAA4ZGXH0wsvvJCmpqacfvrpGTp06AHXPPnkk7nmmmtSV1eXu+++O1OmTMltt92WVatWdVq3YsWKNDQ05GMf+1gaGxtz+umnZ/bs2Xn++ec7rbvhhhvy6KOP5pZbbklDQ0O2bt2aGTNm5LXXXit3fAAAgEPSq9wbTJgwIR/4wAeSJDfddFN+/vOfd1mzdOnS1NXV5fbbb0+SjB8/Pps3b87ixYszderU9OjRI+3t7Vm+fHmmT5+emTNnJknOPffcTJ48OXfddVcaGhqSJE899VQee+yxNDY2pr6+PkkybNiwTJw4MQ8++GA++tGPHtpnDgAAUIayzzz16PHWN2lvb8/jjz+eSy+9tNPlkydPzrZt2/LMM88kSdauXZvt27d3ethfz549c8kll6SpqSmlUinJ6w//q62tzYUXXtix7tRTT83YsWPT1NRU7vgAAACHpOwzTwezcePG7N69O2eeeWany88666wkSXNzc84+++w0NzcnSZd1Q4cOzc6dO7Nly5YMGjQozc3NGTJkSKqqqroc70c/+tEhz1kqlbJr165Dvv2R0t7enpqamkqP0a21trZ2xDT2TBH2TGf2zMHZM53ZMwdnz3TW2tra6S0cTHfaM6VSqUtrvJkjHk+vvvpqkqS2trbT5fvf3399S0tLqqur07dv307rTjjhhCTJK6+8kkGDBqWlpSX9+/fv8nFqa2s7jnUo2tvb8+yzzx7y7Y+UmpqanHjiiZUeo1tbv359t/gfq7uwZw7OnunMnjk4e6Yze+bg7JkD27BhQ6VH4CjTHfZMe3t7+vTpU2jtEY+n/d6s3t54+YHW7L8X52Dr3uryIqqrqzNixIhDvv2R0t7eXukRur0hQ4a4d+8N7JmDs2c6s2cOzp7pzJ45OHums9bW1mzYsCFnnHGGs5YU0p32THV1deG1Rzye9p85+sOzQi0tLUl+fwaqtrY2bW1taWtr61R6+9ftP05tbW02b97c5eO0tLR0ObtVjqqqqhx33HGHfPsj5XAC8FhR6f+huht75uDsmc7smYOzZzqzZw7Onumqd+/eOe6443xtKEtNTU3Ffycv53veEf8juaeddlp69+6dF198sdPl69atS5KOlzff/3b/c5/2a25uzvHHH59TTjmlY9369eu73Luzbt26N32pdAAA3j5VVVWpqxspnN7Evn3OUv6pOOJnnqqrqzN+/PisXr06f/d3f9dx+cMPP5yBAwemrq4uSTJ27Nj0798/jzzySMdle/fuzerVq1NfX99RgPX19Vm6dGnWrFnT8Yp7mzdvztq1azNv3rwjPT4AAIegV6+e+ef7f5GNW9sqPUq3ctrJffKZK0+v9BgcIWXHU2tra8dLhG/atCk7duzId7/73SSv/52mAQMGZO7cuZk2bVrmzZuXyZMnZ+3atVm1alVuvfXWjpc6r66uztVXX52GhoYMGDAgdXV1WbVqVV566aUsWrSo4+ONHj06F110UW6++ebcdNNN6devXxYvXpzBgwdnypQpR+JrAADAEbBxa1uaf+WFNPjTVXY8/eY3v8n111/f6bL97997770ZN25cxowZk2XLlmXRokV56KGHMmjQoMybNy+XX355p9tdddVVKZVKue+++/Lyyy9n2LBhaWxszPDhwzutu/POO3PHHXdkwYIF2b17d8aNG5clS5Z0eaU+AACAP5ay4+ld73pXnn/++YOuq6+vT319/VuuqaqqyqxZszJr1qy3XNevX78sXLgwCxcuLGtWAACAI+WIv2AEAADAnyLxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAAAKEE8AAAAFiCcAAIACxBMAAEAB4gkAAKAA8QQAAFCAeAIAAChAPAEAABQgngAAAAoQTwAAAAWIJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAeIJAACgAPEEAABQgHgCAAAoQDwBAAAUIJ4AAIC3VVVVVXr37l3pMcomngAA4I/kHf16Zd++UqXH6HZqampSVzcyVVVVlR6lLL0qPQAAAPypOr6mZ3r0qMo/3/+LbNzaVulxuo3TTu6Tz1x5enbvrvQk5RFPAADwR7Zxa1uaf9Va6TE4TB62BwAAUIB4AgAAKEA8AQAAFCCeAAAACjgq4mn9+vWZOXNm3ve+9+W8887Lbbfdltdee63SYwEAAMeQbv9qey0tLfnEJz6RU089Nf/6r/+a3/72t/nCF76QV155JV/+8pcrPR4AAHCM6Pbx9M1vfjMtLS156KGHMmDAgCRJz5498+lPfzpXX311hg4dWuEJAQCAY0G3f9jef/7nf+a8887rCKck+eu//utUV1enqampgpMBAADHkm4fT83NzV3OLlVXV+e0005Lc3NzhaYCAACONd3+YXstLS2pra3tcnltbW1effXVQzrm1q1bs3fv3kyYMOFwxztspVIpPXr0yKs792TP3lKlx+lWtvWsysUP9Uqp5Ovyh6qqquyZA7Bn3pw9c2D2zJuzZw7Mnnlz9syBPdjUI9+/u6evzR/Y///Svn37UlVVVdFZfv3rX6dnz56F1nb7eHozpVLpkL/Qffr0SXt7e8X/QyXpmOGE44/a/xR/dN3hv1N3ZM+8OXvmwOyZN2fPHJg98+bsmQOzZ96cr82B9ehR+QfC9erVK9XV1cXW/pFnOWy1tbVpaWnpcvn27dsP+cUi/uu//utwxwIAAI4xlU+9gxg6dGiX5za1t7dn48aNXmkPAAB423T7eLrwwgvz+OOP53e/+13HZd///vfT3t6e+vr6Ck4GAAAcS6pK3fwZjy0tLZk0aVIGDx6ca665Jr/5zW/yxS9+Meeff74/kgsAALxtun08Jcn69etz22235Sc/+Un69u2bSZMm5dOf/nT69u1b6dEAAIBjxFERTwAAAJXW7Z/zBAAA0B2IJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeKuQXv/hF5s+fnw9/+MOpq6vLpEmTKj0S3dzq1atzzTXXpL6+Pu973/syefLkfOMb38i+ffsqPRrd1Jo1azJt2rSMHz8+Z599di6++OJ84QtfyPbt2ys9GkeBnTt35sILL8zw4cPzs5/9rNLj0A098MADGT58eJd/vvzlL1d6NLq5VatW5UMf+lBGjRqV8847L3PmzKn0SIX1qvQAx6oXXnghTU1NGT16dPbt2xd/q5iD+drXvpZTTz01n/nMZ3LSSSfliSeeyOc///m89NJL+exnP1vp8eiGXn311YwZMyaf+MQnUltbmxdeeCFLlizJCy+8kK9+9auVHo9ubtmyZdm7d2+lx+AocM8996R///4d759yyikVnIbubsmSJfn3f//3zJkzJ6NHj86rr76aNWvWVHqswsRThUyYMCEf+MAHkiQ33XRTfv7zn1d4Irq7u+66KwMGDOh4f/z48dm1a1dWrlyZT33qU6murq7gdHRHkyZN6nRWe9y4camurs4tt9ySLVu2+AWHN9Xc3JxvfOMb+exnP5t/+qd/qvQ4dHMjR47s9PMJ3kxzc3OWL1+exsbGnH/++R2XT5w4sYJTlcfD9iqkRw9fespzoB9MI0aMSFtbW1555ZW3fyCOSieeeGKSZM+ePZUdhG7t85//fD7ykY9kyJAhlR4F+BPywAMP5N3vfnencDra+A0ejmI/+clPcuKJJ+akk06q9Ch0Y3v37k1bW1uefvrpLF26NO9///szePDgSo9FN/Xd7343zz33XObOnVvpUThKTJo0KSNGjMjFF1+cf/u3f/NwT97UU089lWHDhmXp0qU577zzcvbZZ2fatGl59tlnKz1aYR62B0epn/3sZ3nggQcyd+7c9OzZs9Lj0I29//3vz5YtW5IkF1xwQRYtWlThieiuWltb88UvfjH/8A//kH79+lV6HLq5gQMH5tprr83o0aNTVVWVRx99NP/yL/+SLVu2ZP78+ZUej25o27Ztefrpp/PCCy9kwYIF6d27d77yla9kxowZ+d73vpfa2tpKj3hQ4gmOQtu2bct1112XUaNGZfbs2ZUeh26usbExu3btyrp167Js2bLMmTMnX/va10Q3XSxfvjwnnXRS/uZv/qbSo3AUuOCCC3LBBRd0vH/++eenT58++Y//+I/MmTMnJ598cgWnozsqlUrZtWtXlixZkj/7sz9L8vpz5i6++OLcf//9R8XvNB62B0eZ7du3Z/bs2enbt2+WL1+e3r17V3okurn3vOc9GTt2bK644op85StfyRNPPJHvf//7lR6LbmbTpk356le/muuuuy47duxIS0tLdu3alSTZtWtXdu7cWeEJORp88IMfzN69e4+qh2Hx9jnhhBPyzne+syOckuTkk0/OmWeemXXr1lVwsuKceYKjSFtbW66++uq8/PLLuf/++/OOd7yj0iNxlBkxYkR69uyZjRs3VnoUuplf/vKX2b17dz75yU92uW769OkZPXp0vvWtb1VgMuBPxdChQ/OrX/2qy+WlUumoeTE18QRHiT179uT666/Pc889l69//eue8M8hefLJJ7N37968613vqvQodDMjRozIvffe2+myZ599Nl/4wheyYMGCjBo1qkKTcTR55JFH0rNnz9TV1VV6FLqhiy66KA8++GD++7//O8OGDUuSbNmyJS+++OJR83Bh8VQhra2taWpqSvL6QyV27NiR7373u0mSc889199LoItbb701P/zhD3PjjTfmtddey09/+tOO68466yxP7qaLv//7v8/ZZ5+d4cOHp2/fvnnuuedyzz33ZPjw4R1/Zw72q62tzbhx4w543ciRIzNy5Mi3eSK6u5kzZ2b8+PEdvwT/4Ac/yLe+9a1Mnz49AwcOrPB0dEcTJ07MyJEjc+211+b6669PdXV1li5dmgEDBuSKK66o9HiFVJVKpVKlhzgW/fKXv8zFF198wOvuvffeN/0BxrFrwoQJ2bRp0wGvs2c4kMbGxjzyyCPZuHFjSqVSBg8enIkTJ2bmzJlim0KeeOKJTJ8+Pd/+9redeaKL2267LWvWrMmvf/3r7Nu3L2eccUYuv/zyfPzjH09VVVWlx6Ob+s1vfpPbb789TU1N2bNnT84555z84z/+Y84888xKj1aIeAIAACjg6HhmFgAAQIWJJwAAgALEEwAAQAHiCQAAoADxBAAAUIB4AgAAKEA8AQAAFCCeAAAAChBPAAAABYgnAACAAsQTAABAAf8fveO1RtjUVpEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to set the random seed for reproducibility\n",
    "def seed_all(seed_value):\n",
    "    \"\"\"\n",
    "    Setting the random seed across the pipeline\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed_value) # cpu vars\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  # needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 1337\n",
    "seed_all(seed)\n",
    "\n",
    "# Read the datasets\n",
    "train_df = pd.read_csv(\"/home/jovyan/AES/train.csv\", sep=',', encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv(\"/home/jovyan/AES/test.csv\", sep=',', encoding='ISO-8859-1')\n",
    "\n",
    "# Verify column names\n",
    "print(f\"Columns in the training dataset: {train_df.columns}\")\n",
    "print(f\"Columns in the test dataset: {test_df.columns}\")\n",
    "\n",
    "\n",
    "# Select the 'domain1_score' column for comparison\n",
    "train_scores = train_df[\"score\"]\n",
    "\n",
    "# Perform KS test within the training dataset\n",
    "train, val = train_test_split(train_df, test_size=0.1, stratify=train_df[['score']])\n",
    "train_scores = train[\"score\"]\n",
    "val_scores = val[\"score\"]\n",
    "\n",
    "test_statistic, p_value = stats.ks_2samp(train_scores, val_scores)\n",
    "print(f\"KS test result: statistic={test_statistic}, p-value={p_value}\")\n",
    "\n",
    "# Plot the distribution\n",
    "def plot_distribution(df, target_col):\n",
    "    \"\"\"\n",
    "    Shows distribution\n",
    "    \"\"\"\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Column '{target_col}' not found in DataFrame columns: {df.columns}\")\n",
    "        return\n",
    "\n",
    "    df = df[[target_col]]\n",
    "    distribution = df[target_col].value_counts(normalize=True) * 100\n",
    "    print(distribution)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=distribution.index, y=distribution.values, palette=\"muted\")\n",
    "    plt.title('Distribution of Scores')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.show()\n",
    "\n",
    "    df.hist(figsize=(10, 7))\n",
    "    plt.show()\n",
    "\n",
    "# Set the style for the plots\n",
    "sns.set(color_codes=True)\n",
    "sns.set(style=\"white\", palette=\"muted\")\n",
    "\n",
    "# Plot the distribution\n",
    "plot_distribution(train_df, 'score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:19:48.601065Z",
     "iopub.status.busy": "2024-06-02T09:19:48.600329Z",
     "iopub.status.idle": "2024-06-02T09:19:48.617527Z",
     "shell.execute_reply": "2024-06-02T09:19:48.616948Z",
     "shell.execute_reply.started": "2024-06-02T09:19:48.601018Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15576.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.948254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.044816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score\n",
       "count  15576.000000\n",
       "mean       2.948254\n",
       "std        1.044816\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        4.000000\n",
       "max        6.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The 1cycle policy was introduced by Leslie N. Smith et al. in Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates. It schedules the learning rate with a cosine annealing from lr_max/div to lr_max then lr_max/div_final (pass an array to lr_max if you want to use differential learning rates) and the momentum with cosine annealing according to the values in moms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export and load t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can add weight regularization to the hidden layer to reduce the overfitting of the model to the training dataset and improve the performance on the holdout set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unfreezing all the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our model is overffiting from previous epoch so increase regularization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further improvement using hyperparameter tuning and k-fold stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:40:15.147380Z",
     "iopub.status.busy": "2024-06-02T09:40:15.146812Z",
     "iopub.status.idle": "2024-06-02T09:40:21.525074Z",
     "shell.execute_reply": "2024-06-02T09:40:21.524274Z",
     "shell.execute_reply.started": "2024-06-02T09:40:15.147345Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "   essay_id  \\\n",
      "0  000d118   \n",
      "1  000fe60   \n",
      "2  001ab80   \n",
      "3  001bdc0   \n",
      "4  002ba53   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \\\n",
      "0  Many people have car where they live. The thing they don't know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban's families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won't see a car in Vauban's streets because they are completely \"car free\" but If some that lives in...   \n",
      "1  I am a scientist at NASA that is discussing the \"face\" on mars. I will be explaining how the \"face\" is a land form. By sharing my information about this isue i will tell you just that.\\n\\nFirst off, how could it be a martions drawing. There is no plant life on mars as of rite now that we know of, which means so far as we know it is not possible for any type of life. That explains how it could not be made by martians. Also why and how would a martion build a face so big. It just does not make any since that a martian did this.\\n\\nNext, why it is a landform. There are many landforms that are...   \n",
      "2  People always wish they had the same technology that they have seen in movies, or the best new piece of technology that is all over social media. However, nobody seems to think of the risks that these kinds of new technologies may have. Cars have been around for many decades, and now manufacturers are starting to get on the bandwagon and come up with the new and improved technology that they hope will appeal to everyone. As of right now, it seems as though the negative characteristics of these cars consume the positive idea that these manufacturers have tried to convey.\\n\\nCurrently, this ...   \n",
      "3  We all heard about Venus, the planet without almost oxygen with earthquakes, erupting volcanoes and temperatures average over 800 degrees Fahrenheit but what if scientist project the futur into this planet ? Through this article, the author uses evidences appealing to reason and concession to make us realize why we should care about studying this planet so that people must give a chance to Venus.\\n\\nVenus is the closest planet to Earth in terms density and size but has a really different climate. As it is evoked by the author:\\n\\n( 3) \"A thick atmosphere of almost 97 percent carbon dioxide...   \n",
      "4  Dear, State Senator\\n\\nThis is a letter to argue in favor of keeping the Electoral College.\"There are many reasons to keep the Electoral College\" one reason is because it is widely regarded as an anachronism, a dispute over the outcome of an Electoral College vote is possible, but it is less likely than a dispute over the popular vote, and the Electoral College restores some of the weight in the political balance that large states (by population) lose by virue of the mal apportionment of the Senate decreed in the Constitution.\\n\\nI am in favor of keeping the Electoral College because,it is...   \n",
      "\n",
      "   score  \n",
      "0      3  \n",
      "1      3  \n",
      "2      4  \n",
      "3      4  \n",
      "4      3  \n",
      "\n",
      "Data type of 'full_text' column: object\n",
      "\n",
      "Missing values:\n",
      " essay_id     0\n",
      "full_text    0\n",
      "score        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel(\n",
       "  (transformer): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes - Input IDs: torch.Size([16, 72]) Outputs: torch.Size([16, 6]) Labels: torch.Size([16])\n",
      "\n",
      "Setup completed successfully!\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Collection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "\n",
    "# Load your dataset\n",
    "train_df = pd.read_csv('/home/jovyan/AES/train.csv')  # Update with the correct path if needed\n",
    "\n",
    "# Print the first few rows and check for issues\n",
    "print(\"First few rows:\\n\", train_df.head())\n",
    "if train_df.empty:\n",
    "    raise ValueError(\"The DataFrame is empty. Check if the CSV file has data.\")\n",
    "print(\"\\nData type of 'full_text' column:\", train_df['full_text'].dtype)\n",
    "print(\"\\nMissing values:\\n\", train_df.isna().sum())\n",
    "\n",
    "# Model and tokenizer setup\n",
    "pretrained_model_name = 'roberta-base'\n",
    "transformer_tokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name)\n",
    "pad_idx = transformer_tokenizer.pad_token_id\n",
    "\n",
    "class TransformersTokenizer:\n",
    "    def __init__(self, pretrained_tokenizer: RobertaTokenizer):\n",
    "        self.pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.model_max_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        return [self.tokenizer(t) for t in items]\n",
    "\n",
    "    def tokenizer(self, t: str) -> List[str]:\n",
    "        CLS = self.pretrained_tokenizer.cls_token\n",
    "        SEP = self.pretrained_tokenizer.sep_token\n",
    "        tokens = self.pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens\n",
    "\n",
    "class TransformersVocab:\n",
    "    def __init__(self, tokenizer: RobertaTokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = list(tokenizer.get_vocab().keys())\n",
    "        self.o2i = {v: k for k, v in enumerate(self.vocab)}\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.vocab)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def numericalize(self, t: Collection[str]) -> List[int]:\n",
    "        return [self.o2i[o_] for o_ in t]\n",
    "\n",
    "    def textify(self, nums: Collection[int], sep=' ') -> List[str]:\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return {'vocab': self.vocab, 'tokenizer': self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state: dict):\n",
    "        self.vocab = state['vocab']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.o2i = {v: k for k, v in enumerate(self.vocab)}\n",
    "\n",
    "# Define a PyTorch Dataset for direct use\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = transformer_tokenizer(text, truncation=True, padding='max_length', max_length=72, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Convert labels to numeric\n",
    "label_map = {label: i for i, label in enumerate(train_df['score'].unique())}\n",
    "train_df['label'] = train_df['score'].map(label_map)\n",
    "\n",
    "# Create dataset\n",
    "dataset = TextDataset(train_df['full_text'].tolist(), train_df['label'].tolist())\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "val_split_ratio = 0.1\n",
    "val_size = int(len(dataset) * val_split_ratio)\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "bs = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "# Model setup\n",
    "config = RobertaConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(label_map)\n",
    "config.use_bfloat16 = False\n",
    "config.hidden_dropout_prob = 0.1\n",
    "config.attention_probs_dropout_prob = 0.1\n",
    "\n",
    "transformer_model = RobertaForSequenceClassification.from_pretrained(pretrained_model_name, config=config)\n",
    "\n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: RobertaForSequenceClassification):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        attention_mask = (input_ids != pad_idx).type(input_ids.type()) if attention_mask is None else attention_mask\n",
    "        logits = self.transformer(input_ids, attention_mask=attention_mask)[0]\n",
    "        return logits\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model=transformer_model)\n",
    "\n",
    "# Optional: Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "custom_transformer_model.to(device)\n",
    "\n",
    "# Quick test to ensure everything works\n",
    "for batch in train_dataloader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    \n",
    "    outputs = custom_transformer_model(input_ids, attention_mask)\n",
    "    print(\"Batch shapes - Input IDs:\", input_ids.shape, \"Outputs:\", outputs.shape, \"Labels:\", labels.shape)\n",
    "    break\n",
    "\n",
    "print(\"\\nSetup completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T07:44:12.930460Z",
     "iopub.status.busy": "2024-06-02T07:44:12.929904Z",
     "iopub.status.idle": "2024-06-02T07:53:43.334962Z",
     "shell.execute_reply": "2024-06-02T07:53:43.333167Z",
     "shell.execute_reply.started": "2024-06-02T07:44:12.930411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 974/974 [01:50<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Training Loss: 1.2738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:05<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Validation Accuracy: 0.4353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 974/974 [01:46<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Training Loss: 1.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:05<00:00, 21.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Validation Accuracy: 0.4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 974/974 [01:46<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Training Loss: 1.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:05<00:00, 20.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Validation Accuracy: 0.4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 974/974 [01:47<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Training Loss: 1.1226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:05<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Validation Accuracy: 0.4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 974/974 [01:47<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Training Loss: 1.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 109/109 [00:05<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Validation Accuracy: 0.4451\n",
      "Model saved successfully!\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm  # Add tqdm for progress bar\n",
    "\n",
    "# Assuming custom_transformer_model, dataloader, and validation_dataloader are already defined\n",
    "\n",
    "# Set up the optimizer and learning rate scheduler\n",
    "optimizer = AdamW(custom_transformer_model.parameters(), lr=1e-5)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):  # Add tqdm here\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        logits = outputs if not isinstance(outputs, dict) else outputs.logits\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):  # Add tqdm here\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs if not isinstance(outputs, dict) else outputs.logits\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            \n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "    \n",
    "    accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    avg_train_loss = train_model(custom_transformer_model, dataloader, optimizer, loss_fn, device)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}')\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    validation_accuracy = evaluate_model(custom_transformer_model, val_dataloader, device)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {validation_accuracy:.4f}')\n",
    "    \n",
    "    scheduler.step()  # Adjust the learning rate\n",
    "\n",
    "# Save the model\n",
    "model_save_path = 'roberta_finetuned.pth'\n",
    "torch.save(custom_transformer_model.state_dict(), model_save_path)\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "print(\"Training completed successfully!\")\n",
    "after this i want to test my test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T08:50:35.850068Z",
     "iopub.status.busy": "2024-06-02T08:50:35.849371Z",
     "iopub.status.idle": "2024-06-02T08:50:39.205150Z",
     "shell.execute_reply": "2024-06-02T08:50:39.203315Z",
     "shell.execute_reply.started": "2024-06-02T08:50:35.850021Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in /opt/conda/lib/python3.9/site-packages (1.1.4)\n",
      "Requirement already satisfied: click<8.0,>=5.1 in /opt/conda/lib/python3.9/site-packages (from Flask) (7.1.2)\n",
      "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /opt/conda/lib/python3.9/site-packages (from Flask) (2.11.3)\n",
      "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /opt/conda/lib/python3.9/site-packages (from Flask) (0.16.1)\n",
      "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /opt/conda/lib/python3.9/site-packages (from Flask) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.9/site-packages (from Jinja2<3.0,>=2.10.1->Flask) (2.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:40:36.888483Z",
     "iopub.status.busy": "2024-06-02T09:40:36.887745Z",
     "iopub.status.idle": "2024-06-02T09:40:38.636556Z",
     "shell.execute_reply": "2024-06-02T09:40:38.635983Z",
     "shell.execute_reply.started": "2024-06-02T09:40:36.888435Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel(\n",
       "  (transformer): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the test dataset:\n",
      "   essay_id  \\\n",
      "0  000d118   \n",
      "1  000fe60   \n",
      "2  001ab80   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \n",
      "0  Many people have car where they live. The thing they don't know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban's families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won't see a car in Vauban's streets because they are completely \"car free\" but If some that lives in...  \n",
      "1  I am a scientist at NASA that is discussing the \"face\" on mars. I will be explaining how the \"face\" is a land form. By sharing my information about this isue i will tell you just that.\\n\\nFirst off, how could it be a martions drawing. There is no plant life on mars as of rite now that we know of, which means so far as we know it is not possible for any type of life. That explains how it could not be made by martians. Also why and how would a martion build a face so big. It just does not make any since that a martian did this.\\n\\nNext, why it is a landform. There are many landforms that are...  \n",
      "2  People always wish they had the same technology that they have seen in movies, or the best new piece of technology that is all over social media. However, nobody seems to think of the risks that these kinds of new technologies may have. Cars have been around for many decades, and now manufacturers are starting to get on the bandwagon and come up with the new and improved technology that they hope will appeal to everyone. As of right now, it seems as though the negative characteristics of these cars consume the positive idea that these manufacturers have tried to convey.\\n\\nCurrently, this ...  \n",
      "\n",
      "Data type of 'full_text' column: object\n",
      "\n",
      "Missing values:\n",
      " essay_id     0\n",
      "full_text    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<00:00, 38.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Update the number of labels in the configuration\n",
    "config.num_labels = 6  # Update this number to match the number of labels in your dataset\n",
    "\n",
    "# Custom model definition used during training\n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: RobertaForSequenceClassification, num_labels=6):  # Update num_labels\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.transformer.classifier.out_proj = nn.Linear(self.transformer.config.hidden_size, num_labels)  # Update classifier output size\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).type(input_ids.type()) if attention_mask is None else attention_mask\n",
    "        logits = self.transformer(input_ids, attention_mask=attention_mask)[0]\n",
    "        return logits\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "pretrained_model_name = \"roberta-base\"\n",
    "saved_model_path = \"roberta_finetuned.pth\"\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name)\n",
    "base_model = RobertaForSequenceClassification.from_pretrained(pretrained_model_name)\n",
    "\n",
    "# Wrap the base model with the custom class\n",
    "model = CustomTransformerModel(transformer_model=base_model, num_labels=6)  # Update num_labels\n",
    "model.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Define batch size\n",
    "bs = 8  # Update as needed\n",
    "\n",
    "# Load your test dataset\n",
    "test_df = pd.read_csv('/home/jovyan/AES/test.csv')  # Update with the correct path if needed\n",
    "\n",
    "# Print the first few rows and check for issues\n",
    "print(\"First few rows of the test dataset:\\n\", test_df.head())\n",
    "if test_df.empty:\n",
    "    raise ValueError(\"The test DataFrame is empty. Check if the CSV file has data.\")\n",
    "print(\"\\nData type of 'full_text' column:\", test_df['full_text'].dtype)\n",
    "print(\"\\nMissing values:\\n\", test_df.isna().sum())\n",
    "\n",
    "# Define a custom Dataset class for the test data\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = tokenizer(text, truncation=True, padding='max_length', max_length=72, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = TextDataset(test_df['full_text'].tolist())\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "# Function for predicting labels\n",
    "def predict_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting\"):  # Add tqdm here\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs if not isinstance(outputs, dict) else outputs.logits\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = predict_model(model, test_dataloader, device)\n",
    "\n",
    "# Optionally, you can save the predictions to a CSV file\n",
    "test_df['predicted_score'] = test_predictions\n",
    "test_df.to_csv('/home/jovyan/AES/test_predictions.csv', index=False)\n",
    "print(\"Test predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:40:58.418902Z",
     "iopub.status.busy": "2024-06-02T09:40:58.418212Z",
     "iopub.status.idle": "2024-06-02T09:40:58.444800Z",
     "shell.execute_reply": "2024-06-02T09:40:58.444198Z",
     "shell.execute_reply.started": "2024-06-02T09:40:58.418855Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 4\n"
     ]
    }
   ],
   "source": [
    "def predict_single_text(text, model, tokenizer, device):\n",
    "    # Tokenize the input text\n",
    "    encoding = tokenizer(text, truncation=True, padding='max_length', max_length=365, return_tensors='pt')\n",
    "    \n",
    "    # Move tensors to the appropriate device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Predict the label\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "        logits = output if not isinstance(output, dict) else output.logits\n",
    "        _, predicted = torch.max(logits, dim=1)\n",
    "    \n",
    "    # Return the predicted label\n",
    "    return predicted.item()\n",
    "\n",
    "# Example usage:\n",
    "input_text = \"In today's digital age, technology has revolutionized the field of education, transforming the way students learn and teachers teach. The integration of technology into education has had a profound impact on various aspects, including accessibility, engagement, and personalized learning. how many characters\"\n",
    "predicted_label = predict_single_text(input_text, model, tokenizer, device)\n",
    "print(\"Predicted label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:21:53.069030Z",
     "iopub.status.busy": "2024-06-02T09:21:53.068297Z",
     "iopub.status.idle": "2024-06-02T09:23:03.806370Z",
     "shell.execute_reply": "2024-06-02T09:23:03.804729Z",
     "shell.execute_reply.started": "2024-06-02T09:21:53.068984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - jinja2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.6.2   |       hbcca054_0         152 KB  conda-forge\n",
      "    conda-22.11.1              |   py39hf3d152e_1         904 KB  conda-forge\n",
      "    jinja2-3.1.4               |     pyhd8ed1ab_0         109 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.1 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                       2024.2.2-hbcca054_0 --> 2024.6.2-hbcca054_0 None\n",
      "  conda                               22.9.0-py39hf3d152e_1 --> 22.11.1-py39hf3d152e_1 None\n",
      "  jinja2                                 3.1.2-pyhd8ed1ab_1 --> 3.1.4-pyhd8ed1ab_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-22.11.1        | 904 KB    | ##################################### | 100% \n",
      "jinja2-3.1.4         | 109 KB    | ##################################### | 100% \n",
      "ca-certificates-2024 | 152 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:42:48.554875Z",
     "iopub.status.busy": "2024-06-02T09:42:48.554248Z",
     "iopub.status.idle": "2024-06-02T09:42:51.784231Z",
     "shell.execute_reply": "2024-06-02T09:42:51.782452Z",
     "shell.execute_reply.started": "2024-06-02T09:42:48.554815Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.9/site-packages (0.110.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.9/site-packages (0.27.1)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /opt/conda/lib/python3.9/site-packages (from fastapi) (0.36.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from fastapi) (2.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from fastapi) (4.10.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.9/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from uvicorn) (7.1.2)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from starlette<0.37.0,>=0.36.3->fastapi) (3.6.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastapi uvicorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): RobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the test dataset:\n",
      "   essay_id  \\\n",
      "0  000d118   \n",
      "1  000fe60   \n",
      "2  001ab80   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 full_text  \n",
      "0  Many people have car where they live. The thing they don't know is that when you use a car alot of thing can happen like you can get in accidet or the smoke that the car has is bad to breath on if someone is walk but in VAUBAN,Germany they dont have that proble because 70 percent of vauban's families do not own cars,and 57 percent sold a car to move there. Street parkig ,driveways and home garages are forbidden on the outskirts of freiburd that near the French and Swiss borders. You probaly won't see a car in Vauban's streets because they are completely \"car free\" but If some that lives in...  \n",
      "1  I am a scientist at NASA that is discussing the \"face\" on mars. I will be explaining how the \"face\" is a land form. By sharing my information about this isue i will tell you just that.\\n\\nFirst off, how could it be a martions drawing. There is no plant life on mars as of rite now that we know of, which means so far as we know it is not possible for any type of life. That explains how it could not be made by martians. Also why and how would a martion build a face so big. It just does not make any since that a martian did this.\\n\\nNext, why it is a landform. There are many landforms that are...  \n",
      "2  People always wish they had the same technology that they have seen in movies, or the best new piece of technology that is all over social media. However, nobody seems to think of the risks that these kinds of new technologies may have. Cars have been around for many decades, and now manufacturers are starting to get on the bandwagon and come up with the new and improved technology that they hope will appeal to everyone. As of right now, it seems as though the negative characteristics of these cars consume the positive idea that these manufacturers have tried to convey.\\n\\nCurrently, this ...  \n",
      "\n",
      "Data type of 'full_text' column: object\n",
      "\n",
      "Missing values:\n",
      " essay_id     0\n",
      "full_text    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<00:00, 36.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Update the number of labels in the configuration\n",
    "config.num_labels = 6  # Update this number to match the number of labels in your dataset\n",
    "\n",
    "# Custom model definition used during training\n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: RobertaForSequenceClassification, num_labels=6):  # Update num_labels\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.transformer.classifier.out_proj = nn.Linear(self.transformer.config.hidden_size, num_labels)  # Update classifier output size\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).type(input_ids.type()) if attention_mask is None else attention_mask\n",
    "        logits = self.transformer(input_ids, attention_mask=attention_mask)[0]\n",
    "        return logits\n",
    "\n",
    "# Load the saved model\n",
    "pretrained_model_name = \"roberta-base\"\n",
    "saved_model_path = \"roberta_finetuned.pth\"\n",
    "\n",
    "base_model = RobertaForSequenceClassification.from_pretrained(pretrained_model_name)\n",
    "\n",
    "# Wrap the base model with the custom class\n",
    "model = CustomTransformerModel(transformer_model=base_model, num_labels=6)  # Update num_labels\n",
    "model.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define batch size\n",
    "bs = 8  # Update as needed\n",
    "\n",
    "# Load your test dataset\n",
    "test_df = pd.read_csv('/home/jovyan/AES/test.csv')  # Update with the correct path if needed\n",
    "\n",
    "# Print the first few rows and check for issues\n",
    "print(\"First few rows of the test dataset:\\n\", test_df.head())\n",
    "if test_df.empty:\n",
    "    raise ValueError(\"The test DataFrame is empty. Check if the CSV file has data.\")\n",
    "print(\"\\nData type of 'full_text' column:\", test_df['full_text'].dtype)\n",
    "print(\"\\nMissing values:\\n\", test_df.isna().sum())\n",
    "\n",
    "# Define a custom Dataset class for the test data\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = tokenizer(text, truncation=True, padding='max_length', max_length=72, return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "        }\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = TextDataset(test_df['full_text'].tolist())\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "# Function for predicting labels\n",
    "def predict_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting\"):  # Add tqdm here\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            logits = outputs if not isinstance(outputs, dict) else outputs.logits\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = predict_model(model, test_dataloader, device)\n",
    "\n",
    "# Optionally, you can save the predictions to a CSV file\n",
    "test_df['predicted_score'] = test_predictions\n",
    "test_df.to_csv('/home/jovyan/AES/test_predictions.csv', index=False)\n",
    "print(\"Test predictions saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:21:53.069030Z",
     "iopub.status.busy": "2024-06-02T09:21:53.068297Z",
     "iopub.status.idle": "2024-06-02T09:23:03.806370Z",
     "shell.execute_reply": "2024-06-02T09:23:03.804729Z",
     "shell.execute_reply.started": "2024-06-02T09:21:53.068984Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - jinja2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.6.2   |       hbcca054_0         152 KB  conda-forge\n",
      "    conda-22.11.1              |   py39hf3d152e_1         904 KB  conda-forge\n",
      "    jinja2-3.1.4               |     pyhd8ed1ab_0         109 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.1 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                       2024.2.2-hbcca054_0 --> 2024.6.2-hbcca054_0 None\n",
      "  conda                               22.9.0-py39hf3d152e_1 --> 22.11.1-py39hf3d152e_1 None\n",
      "  jinja2                                 3.1.2-pyhd8ed1ab_1 --> 3.1.4-pyhd8ed1ab_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "conda-22.11.1        | 904 KB    | ##################################### | 100% \n",
      "jinja2-3.1.4         | 109 KB    | ##################################### | 100% \n",
      "ca-certificates-2024 | 152 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge jinja2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T03:30:06.131751Z",
     "iopub.status.busy": "2024-06-03T03:30:06.131031Z",
     "iopub.status.idle": "2024-06-03T03:30:06.147564Z",
     "shell.execute_reply": "2024-06-03T03:30:06.146844Z",
     "shell.execute_reply.started": "2024-06-03T03:30:06.131689Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa Score: 0.5714\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Load the test predictions CSV file\n",
    "test_predictions_df = pd.read_csv('/home/jovyan/AES/test_predictions.csv')\n",
    "\n",
    "# Extract predicted labels from the test predictions CSV\n",
    "predicted_labels = test_predictions_df['predicted_score'].tolist()  # Assuming 'predicted_score' is the column name containing predicted labels\n",
    "\n",
    "# True labels provided as a list\n",
    "true_labels = [3, 2, 1]  # Replace with your actual true labels\n",
    "\n",
    "# Calculate Cohen's Kappa score\n",
    "kappa_score = cohen_kappa_score(true_labels, predicted_labels)\n",
    "print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-02T09:42:48.554875Z",
     "iopub.status.busy": "2024-06-02T09:42:48.554248Z",
     "iopub.status.idle": "2024-06-02T09:42:51.784231Z",
     "shell.execute_reply": "2024-06-02T09:42:51.782452Z",
     "shell.execute_reply.started": "2024-06-02T09:42:48.554815Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.9/site-packages (0.110.0)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.9/site-packages (0.27.1)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /opt/conda/lib/python3.9/site-packages (from fastapi) (0.36.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from fastapi) (2.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from fastapi) (4.10.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.9/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from uvicorn) (7.1.2)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from starlette<0.37.0,>=0.36.3->fastapi) (3.6.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastapi uvicorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
